// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yarn_service_protos.proto

package org.apache.hadoop.yarn.proto;

public final class YarnServiceProtos {
  private YarnServiceProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  public interface RegisterApplicationMasterRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .ApplicationAttemptIdProto application_attempt_id = 1;
    boolean hasApplicationAttemptId();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder();
    
    // optional string host = 2;
    boolean hasHost();
    String getHost();
    
    // optional int32 rpc_port = 3;
    boolean hasRpcPort();
    int getRpcPort();
    
    // optional string tracking_url = 4;
    boolean hasTrackingUrl();
    String getTrackingUrl();
  }
  public static final class RegisterApplicationMasterRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements RegisterApplicationMasterRequestProtoOrBuilder {
    // Use RegisterApplicationMasterRequestProto.newBuilder() to construct.
    private RegisterApplicationMasterRequestProto(Builder builder) {
      super(builder);
    }
    private RegisterApplicationMasterRequestProto(boolean noInit) {}
    
    private static final RegisterApplicationMasterRequestProto defaultInstance;
    public static RegisterApplicationMasterRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public RegisterApplicationMasterRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_RegisterApplicationMasterRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_RegisterApplicationMasterRequestProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .ApplicationAttemptIdProto application_attempt_id = 1;
    public static final int APPLICATION_ATTEMPT_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_;
    public boolean hasApplicationAttemptId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
      return applicationAttemptId_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
      return applicationAttemptId_;
    }
    
    // optional string host = 2;
    public static final int HOST_FIELD_NUMBER = 2;
    private java.lang.Object host_;
    public boolean hasHost() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public String getHost() {
      java.lang.Object ref = host_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (com.google.protobuf.Internal.isValidUtf8(bs)) {
          host_ = s;
        }
        return s;
      }
    }
    private com.google.protobuf.ByteString getHostBytes() {
      java.lang.Object ref = host_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8((String) ref);
        host_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    
    // optional int32 rpc_port = 3;
    public static final int RPC_PORT_FIELD_NUMBER = 3;
    private int rpcPort_;
    public boolean hasRpcPort() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public int getRpcPort() {
      return rpcPort_;
    }
    
    // optional string tracking_url = 4;
    public static final int TRACKING_URL_FIELD_NUMBER = 4;
    private java.lang.Object trackingUrl_;
    public boolean hasTrackingUrl() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public String getTrackingUrl() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (com.google.protobuf.Internal.isValidUtf8(bs)) {
          trackingUrl_ = s;
        }
        return s;
      }
    }
    private com.google.protobuf.ByteString getTrackingUrlBytes() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8((String) ref);
        trackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    
    private void initFields() {
      applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      host_ = "";
      rpcPort_ = 0;
      trackingUrl_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationAttemptId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getHostBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt32(3, rpcPort_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBytes(4, getTrackingUrlBytes());
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationAttemptId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getHostBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, rpcPort_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, getTrackingUrlBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto) obj;
      
      boolean result = true;
      result = result && (hasApplicationAttemptId() == other.hasApplicationAttemptId());
      if (hasApplicationAttemptId()) {
        result = result && getApplicationAttemptId()
            .equals(other.getApplicationAttemptId());
      }
      result = result && (hasHost() == other.hasHost());
      if (hasHost()) {
        result = result && getHost()
            .equals(other.getHost());
      }
      result = result && (hasRpcPort() == other.hasRpcPort());
      if (hasRpcPort()) {
        result = result && (getRpcPort()
            == other.getRpcPort());
      }
      result = result && (hasTrackingUrl() == other.hasTrackingUrl());
      if (hasTrackingUrl()) {
        result = result && getTrackingUrl()
            .equals(other.getTrackingUrl());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationAttemptId()) {
        hash = (37 * hash) + APPLICATION_ATTEMPT_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationAttemptId().hashCode();
      }
      if (hasHost()) {
        hash = (37 * hash) + HOST_FIELD_NUMBER;
        hash = (53 * hash) + getHost().hashCode();
      }
      if (hasRpcPort()) {
        hash = (37 * hash) + RPC_PORT_FIELD_NUMBER;
        hash = (53 * hash) + getRpcPort();
      }
      if (hasTrackingUrl()) {
        hash = (37 * hash) + TRACKING_URL_FIELD_NUMBER;
        hash = (53 * hash) + getTrackingUrl().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_RegisterApplicationMasterRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_RegisterApplicationMasterRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationAttemptIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        host_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        rpcPort_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        trackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationAttemptIdBuilder_ == null) {
          result.applicationAttemptId_ = applicationAttemptId_;
        } else {
          result.applicationAttemptId_ = applicationAttemptIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.host_ = host_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.rpcPort_ = rpcPort_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.trackingUrl_ = trackingUrl_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationAttemptId()) {
          mergeApplicationAttemptId(other.getApplicationAttemptId());
        }
        if (other.hasHost()) {
          setHost(other.getHost());
        }
        if (other.hasRpcPort()) {
          setRpcPort(other.getRpcPort());
        }
        if (other.hasTrackingUrl()) {
          setTrackingUrl(other.getTrackingUrl());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder();
              if (hasApplicationAttemptId()) {
                subBuilder.mergeFrom(getApplicationAttemptId());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setApplicationAttemptId(subBuilder.buildPartial());
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              host_ = input.readBytes();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              rpcPort_ = input.readInt32();
              break;
            }
            case 34: {
              bitField0_ |= 0x00000008;
              trackingUrl_ = input.readBytes();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .ApplicationAttemptIdProto application_attempt_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> applicationAttemptIdBuilder_;
      public boolean hasApplicationAttemptId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          return applicationAttemptId_;
        } else {
          return applicationAttemptIdBuilder_.getMessage();
        }
      }
      public Builder setApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationAttemptId_ = value;
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setApplicationAttemptId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationAttemptId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            applicationAttemptId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(applicationAttemptId_).mergeFrom(value).buildPartial();
          } else {
            applicationAttemptId_ = value;
          }
          onChanged();
        } else {
          applicationAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getApplicationAttemptIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationAttemptIdFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
        if (applicationAttemptIdBuilder_ != null) {
          return applicationAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationAttemptId_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getApplicationAttemptIdFieldBuilder() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  applicationAttemptId_,
                  getParentForChildren(),
                  isClean());
          applicationAttemptId_ = null;
        }
        return applicationAttemptIdBuilder_;
      }
      
      // optional string host = 2;
      private java.lang.Object host_ = "";
      public boolean hasHost() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public String getHost() {
        java.lang.Object ref = host_;
        if (!(ref instanceof String)) {
          String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
          host_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      public Builder setHost(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        host_ = value;
        onChanged();
        return this;
      }
      public Builder clearHost() {
        bitField0_ = (bitField0_ & ~0x00000002);
        host_ = getDefaultInstance().getHost();
        onChanged();
        return this;
      }
      void setHost(com.google.protobuf.ByteString value) {
        bitField0_ |= 0x00000002;
        host_ = value;
        onChanged();
      }
      
      // optional int32 rpc_port = 3;
      private int rpcPort_ ;
      public boolean hasRpcPort() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public int getRpcPort() {
        return rpcPort_;
      }
      public Builder setRpcPort(int value) {
        bitField0_ |= 0x00000004;
        rpcPort_ = value;
        onChanged();
        return this;
      }
      public Builder clearRpcPort() {
        bitField0_ = (bitField0_ & ~0x00000004);
        rpcPort_ = 0;
        onChanged();
        return this;
      }
      
      // optional string tracking_url = 4;
      private java.lang.Object trackingUrl_ = "";
      public boolean hasTrackingUrl() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public String getTrackingUrl() {
        java.lang.Object ref = trackingUrl_;
        if (!(ref instanceof String)) {
          String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
          trackingUrl_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      public Builder setTrackingUrl(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        trackingUrl_ = value;
        onChanged();
        return this;
      }
      public Builder clearTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00000008);
        trackingUrl_ = getDefaultInstance().getTrackingUrl();
        onChanged();
        return this;
      }
      void setTrackingUrl(com.google.protobuf.ByteString value) {
        bitField0_ |= 0x00000008;
        trackingUrl_ = value;
        onChanged();
      }
      
      // @@protoc_insertion_point(builder_scope:RegisterApplicationMasterRequestProto)
    }
    
    static {
      defaultInstance = new RegisterApplicationMasterRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:RegisterApplicationMasterRequestProto)
  }
  
  public interface RegisterApplicationMasterResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .ResourceProto minimumCapability = 1;
    boolean hasMinimumCapability();
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMinimumCapability();
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMinimumCapabilityOrBuilder();
    
    // optional .ResourceProto maximumCapability = 2;
    boolean hasMaximumCapability();
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMaximumCapability();
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaximumCapabilityOrBuilder();
    
    // repeated .ApplicationACLMapProto application_ACLs = 3;
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> 
        getApplicationACLsList();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index);
    int getApplicationACLsCount();
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
        getApplicationACLsOrBuilderList();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
        int index);
  }
  public static final class RegisterApplicationMasterResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements RegisterApplicationMasterResponseProtoOrBuilder {
    // Use RegisterApplicationMasterResponseProto.newBuilder() to construct.
    private RegisterApplicationMasterResponseProto(Builder builder) {
      super(builder);
    }
    private RegisterApplicationMasterResponseProto(boolean noInit) {}
    
    private static final RegisterApplicationMasterResponseProto defaultInstance;
    public static RegisterApplicationMasterResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public RegisterApplicationMasterResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_RegisterApplicationMasterResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_RegisterApplicationMasterResponseProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .ResourceProto minimumCapability = 1;
    public static final int MINIMUMCAPABILITY_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto minimumCapability_;
    public boolean hasMinimumCapability() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMinimumCapability() {
      return minimumCapability_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMinimumCapabilityOrBuilder() {
      return minimumCapability_;
    }
    
    // optional .ResourceProto maximumCapability = 2;
    public static final int MAXIMUMCAPABILITY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto maximumCapability_;
    public boolean hasMaximumCapability() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMaximumCapability() {
      return maximumCapability_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaximumCapabilityOrBuilder() {
      return maximumCapability_;
    }
    
    // repeated .ApplicationACLMapProto application_ACLs = 3;
    public static final int APPLICATION_ACLS_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> applicationACLs_;
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> getApplicationACLsList() {
      return applicationACLs_;
    }
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
        getApplicationACLsOrBuilderList() {
      return applicationACLs_;
    }
    public int getApplicationACLsCount() {
      return applicationACLs_.size();
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index) {
      return applicationACLs_.get(index);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
        int index) {
      return applicationACLs_.get(index);
    }
    
    private void initFields() {
      minimumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      maximumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      applicationACLs_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, minimumCapability_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, maximumCapability_);
      }
      for (int i = 0; i < applicationACLs_.size(); i++) {
        output.writeMessage(3, applicationACLs_.get(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, minimumCapability_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, maximumCapability_);
      }
      for (int i = 0; i < applicationACLs_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, applicationACLs_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto) obj;
      
      boolean result = true;
      result = result && (hasMinimumCapability() == other.hasMinimumCapability());
      if (hasMinimumCapability()) {
        result = result && getMinimumCapability()
            .equals(other.getMinimumCapability());
      }
      result = result && (hasMaximumCapability() == other.hasMaximumCapability());
      if (hasMaximumCapability()) {
        result = result && getMaximumCapability()
            .equals(other.getMaximumCapability());
      }
      result = result && getApplicationACLsList()
          .equals(other.getApplicationACLsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasMinimumCapability()) {
        hash = (37 * hash) + MINIMUMCAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getMinimumCapability().hashCode();
      }
      if (hasMaximumCapability()) {
        hash = (37 * hash) + MAXIMUMCAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getMaximumCapability().hashCode();
      }
      if (getApplicationACLsCount() > 0) {
        hash = (37 * hash) + APPLICATION_ACLS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationACLsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_RegisterApplicationMasterResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_RegisterApplicationMasterResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getMinimumCapabilityFieldBuilder();
          getMaximumCapabilityFieldBuilder();
          getApplicationACLsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (minimumCapabilityBuilder_ == null) {
          minimumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          minimumCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (maximumCapabilityBuilder_ == null) {
          maximumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          maximumCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (applicationACLsBuilder_ == null) {
          applicationACLs_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          applicationACLsBuilder_.clear();
        }
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (minimumCapabilityBuilder_ == null) {
          result.minimumCapability_ = minimumCapability_;
        } else {
          result.minimumCapability_ = minimumCapabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (maximumCapabilityBuilder_ == null) {
          result.maximumCapability_ = maximumCapability_;
        } else {
          result.maximumCapability_ = maximumCapabilityBuilder_.build();
        }
        if (applicationACLsBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            applicationACLs_ = java.util.Collections.unmodifiableList(applicationACLs_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.applicationACLs_ = applicationACLs_;
        } else {
          result.applicationACLs_ = applicationACLsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.getDefaultInstance()) return this;
        if (other.hasMinimumCapability()) {
          mergeMinimumCapability(other.getMinimumCapability());
        }
        if (other.hasMaximumCapability()) {
          mergeMaximumCapability(other.getMaximumCapability());
        }
        if (applicationACLsBuilder_ == null) {
          if (!other.applicationACLs_.isEmpty()) {
            if (applicationACLs_.isEmpty()) {
              applicationACLs_ = other.applicationACLs_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureApplicationACLsIsMutable();
              applicationACLs_.addAll(other.applicationACLs_);
            }
            onChanged();
          }
        } else {
          if (!other.applicationACLs_.isEmpty()) {
            if (applicationACLsBuilder_.isEmpty()) {
              applicationACLsBuilder_.dispose();
              applicationACLsBuilder_ = null;
              applicationACLs_ = other.applicationACLs_;
              bitField0_ = (bitField0_ & ~0x00000004);
              applicationACLsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getApplicationACLsFieldBuilder() : null;
            } else {
              applicationACLsBuilder_.addAllMessages(other.applicationACLs_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder();
              if (hasMinimumCapability()) {
                subBuilder.mergeFrom(getMinimumCapability());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setMinimumCapability(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder();
              if (hasMaximumCapability()) {
                subBuilder.mergeFrom(getMaximumCapability());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setMaximumCapability(subBuilder.buildPartial());
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addApplicationACLs(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .ResourceProto minimumCapability = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto minimumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> minimumCapabilityBuilder_;
      public boolean hasMinimumCapability() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMinimumCapability() {
        if (minimumCapabilityBuilder_ == null) {
          return minimumCapability_;
        } else {
          return minimumCapabilityBuilder_.getMessage();
        }
      }
      public Builder setMinimumCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (minimumCapabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          minimumCapability_ = value;
          onChanged();
        } else {
          minimumCapabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setMinimumCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (minimumCapabilityBuilder_ == null) {
          minimumCapability_ = builderForValue.build();
          onChanged();
        } else {
          minimumCapabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeMinimumCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (minimumCapabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              minimumCapability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            minimumCapability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(minimumCapability_).mergeFrom(value).buildPartial();
          } else {
            minimumCapability_ = value;
          }
          onChanged();
        } else {
          minimumCapabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearMinimumCapability() {
        if (minimumCapabilityBuilder_ == null) {
          minimumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          minimumCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getMinimumCapabilityBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getMinimumCapabilityFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMinimumCapabilityOrBuilder() {
        if (minimumCapabilityBuilder_ != null) {
          return minimumCapabilityBuilder_.getMessageOrBuilder();
        } else {
          return minimumCapability_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getMinimumCapabilityFieldBuilder() {
        if (minimumCapabilityBuilder_ == null) {
          minimumCapabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  minimumCapability_,
                  getParentForChildren(),
                  isClean());
          minimumCapability_ = null;
        }
        return minimumCapabilityBuilder_;
      }
      
      // optional .ResourceProto maximumCapability = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto maximumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> maximumCapabilityBuilder_;
      public boolean hasMaximumCapability() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMaximumCapability() {
        if (maximumCapabilityBuilder_ == null) {
          return maximumCapability_;
        } else {
          return maximumCapabilityBuilder_.getMessage();
        }
      }
      public Builder setMaximumCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (maximumCapabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          maximumCapability_ = value;
          onChanged();
        } else {
          maximumCapabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setMaximumCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (maximumCapabilityBuilder_ == null) {
          maximumCapability_ = builderForValue.build();
          onChanged();
        } else {
          maximumCapabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeMaximumCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (maximumCapabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              maximumCapability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            maximumCapability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(maximumCapability_).mergeFrom(value).buildPartial();
          } else {
            maximumCapability_ = value;
          }
          onChanged();
        } else {
          maximumCapabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearMaximumCapability() {
        if (maximumCapabilityBuilder_ == null) {
          maximumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          maximumCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getMaximumCapabilityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getMaximumCapabilityFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaximumCapabilityOrBuilder() {
        if (maximumCapabilityBuilder_ != null) {
          return maximumCapabilityBuilder_.getMessageOrBuilder();
        } else {
          return maximumCapability_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getMaximumCapabilityFieldBuilder() {
        if (maximumCapabilityBuilder_ == null) {
          maximumCapabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  maximumCapability_,
                  getParentForChildren(),
                  isClean());
          maximumCapability_ = null;
        }
        return maximumCapabilityBuilder_;
      }
      
      // repeated .ApplicationACLMapProto application_ACLs = 3;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> applicationACLs_ =
        java.util.Collections.emptyList();
      private void ensureApplicationACLsIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          applicationACLs_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto>(applicationACLs_);
          bitField0_ |= 0x00000004;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> applicationACLsBuilder_;
      
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> getApplicationACLsList() {
        if (applicationACLsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applicationACLs_);
        } else {
          return applicationACLsBuilder_.getMessageList();
        }
      }
      public int getApplicationACLsCount() {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.size();
        } else {
          return applicationACLsBuilder_.getCount();
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index) {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.get(index);
        } else {
          return applicationACLsBuilder_.getMessage(index);
        }
      }
      public Builder setApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.set(index, value);
          onChanged();
        } else {
          applicationACLsBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addApplicationACLs(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(value);
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(index, value);
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addApplicationACLs(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllApplicationACLs(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> values) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          super.addAll(values, applicationACLs_);
          onChanged();
        } else {
          applicationACLsBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearApplicationACLs() {
        if (applicationACLsBuilder_ == null) {
          applicationACLs_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          applicationACLsBuilder_.clear();
        }
        return this;
      }
      public Builder removeApplicationACLs(int index) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.remove(index);
          onChanged();
        } else {
          applicationACLsBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder getApplicationACLsBuilder(
          int index) {
        return getApplicationACLsFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
          int index) {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.get(index);  } else {
          return applicationACLsBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
           getApplicationACLsOrBuilderList() {
        if (applicationACLsBuilder_ != null) {
          return applicationACLsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applicationACLs_);
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder addApplicationACLsBuilder() {
        return getApplicationACLsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance());
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder addApplicationACLsBuilder(
          int index) {
        return getApplicationACLsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder> 
           getApplicationACLsBuilderList() {
        return getApplicationACLsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
          getApplicationACLsFieldBuilder() {
        if (applicationACLsBuilder_ == null) {
          applicationACLsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder>(
                  applicationACLs_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          applicationACLs_ = null;
        }
        return applicationACLsBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:RegisterApplicationMasterResponseProto)
    }
    
    static {
      defaultInstance = new RegisterApplicationMasterResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:RegisterApplicationMasterResponseProto)
  }
  
  public interface FinishApplicationMasterRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .ApplicationAttemptIdProto application_attempt_id = 1;
    boolean hasApplicationAttemptId();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder();
    
    // optional string diagnostics = 2;
    boolean hasDiagnostics();
    String getDiagnostics();
    
    // optional string tracking_url = 3;
    boolean hasTrackingUrl();
    String getTrackingUrl();
    
    // optional .FinalApplicationStatusProto final_application_status = 4;
    boolean hasFinalApplicationStatus();
    org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus();
  }
  public static final class FinishApplicationMasterRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements FinishApplicationMasterRequestProtoOrBuilder {
    // Use FinishApplicationMasterRequestProto.newBuilder() to construct.
    private FinishApplicationMasterRequestProto(Builder builder) {
      super(builder);
    }
    private FinishApplicationMasterRequestProto(boolean noInit) {}
    
    private static final FinishApplicationMasterRequestProto defaultInstance;
    public static FinishApplicationMasterRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public FinishApplicationMasterRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_FinishApplicationMasterRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_FinishApplicationMasterRequestProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .ApplicationAttemptIdProto application_attempt_id = 1;
    public static final int APPLICATION_ATTEMPT_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_;
    public boolean hasApplicationAttemptId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
      return applicationAttemptId_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
      return applicationAttemptId_;
    }
    
    // optional string diagnostics = 2;
    public static final int DIAGNOSTICS_FIELD_NUMBER = 2;
    private java.lang.Object diagnostics_;
    public boolean hasDiagnostics() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public String getDiagnostics() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (com.google.protobuf.Internal.isValidUtf8(bs)) {
          diagnostics_ = s;
        }
        return s;
      }
    }
    private com.google.protobuf.ByteString getDiagnosticsBytes() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8((String) ref);
        diagnostics_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    
    // optional string tracking_url = 3;
    public static final int TRACKING_URL_FIELD_NUMBER = 3;
    private java.lang.Object trackingUrl_;
    public boolean hasTrackingUrl() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public String getTrackingUrl() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (com.google.protobuf.Internal.isValidUtf8(bs)) {
          trackingUrl_ = s;
        }
        return s;
      }
    }
    private com.google.protobuf.ByteString getTrackingUrlBytes() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8((String) ref);
        trackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    
    // optional .FinalApplicationStatusProto final_application_status = 4;
    public static final int FINAL_APPLICATION_STATUS_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto finalApplicationStatus_;
    public boolean hasFinalApplicationStatus() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus() {
      return finalApplicationStatus_;
    }
    
    private void initFields() {
      applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      diagnostics_ = "";
      trackingUrl_ = "";
      finalApplicationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationAttemptId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeEnum(4, finalApplicationStatus_.getNumber());
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationAttemptId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getDiagnosticsBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getTrackingUrlBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, finalApplicationStatus_.getNumber());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto) obj;
      
      boolean result = true;
      result = result && (hasApplicationAttemptId() == other.hasApplicationAttemptId());
      if (hasApplicationAttemptId()) {
        result = result && getApplicationAttemptId()
            .equals(other.getApplicationAttemptId());
      }
      result = result && (hasDiagnostics() == other.hasDiagnostics());
      if (hasDiagnostics()) {
        result = result && getDiagnostics()
            .equals(other.getDiagnostics());
      }
      result = result && (hasTrackingUrl() == other.hasTrackingUrl());
      if (hasTrackingUrl()) {
        result = result && getTrackingUrl()
            .equals(other.getTrackingUrl());
      }
      result = result && (hasFinalApplicationStatus() == other.hasFinalApplicationStatus());
      if (hasFinalApplicationStatus()) {
        result = result &&
            (getFinalApplicationStatus() == other.getFinalApplicationStatus());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationAttemptId()) {
        hash = (37 * hash) + APPLICATION_ATTEMPT_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationAttemptId().hashCode();
      }
      if (hasDiagnostics()) {
        hash = (37 * hash) + DIAGNOSTICS_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnostics().hashCode();
      }
      if (hasTrackingUrl()) {
        hash = (37 * hash) + TRACKING_URL_FIELD_NUMBER;
        hash = (53 * hash) + getTrackingUrl().hashCode();
      }
      if (hasFinalApplicationStatus()) {
        hash = (37 * hash) + FINAL_APPLICATION_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getFinalApplicationStatus());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_FinishApplicationMasterRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_FinishApplicationMasterRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationAttemptIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        diagnostics_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        trackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        finalApplicationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationAttemptIdBuilder_ == null) {
          result.applicationAttemptId_ = applicationAttemptId_;
        } else {
          result.applicationAttemptId_ = applicationAttemptIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.diagnostics_ = diagnostics_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.trackingUrl_ = trackingUrl_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.finalApplicationStatus_ = finalApplicationStatus_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationAttemptId()) {
          mergeApplicationAttemptId(other.getApplicationAttemptId());
        }
        if (other.hasDiagnostics()) {
          setDiagnostics(other.getDiagnostics());
        }
        if (other.hasTrackingUrl()) {
          setTrackingUrl(other.getTrackingUrl());
        }
        if (other.hasFinalApplicationStatus()) {
          setFinalApplicationStatus(other.getFinalApplicationStatus());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder();
              if (hasApplicationAttemptId()) {
                subBuilder.mergeFrom(getApplicationAttemptId());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setApplicationAttemptId(subBuilder.buildPartial());
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              diagnostics_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              trackingUrl_ = input.readBytes();
              break;
            }
            case 32: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto value = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(4, rawValue);
              } else {
                bitField0_ |= 0x00000008;
                finalApplicationStatus_ = value;
              }
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .ApplicationAttemptIdProto application_attempt_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> applicationAttemptIdBuilder_;
      public boolean hasApplicationAttemptId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          return applicationAttemptId_;
        } else {
          return applicationAttemptIdBuilder_.getMessage();
        }
      }
      public Builder setApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationAttemptId_ = value;
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setApplicationAttemptId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationAttemptId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            applicationAttemptId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(applicationAttemptId_).mergeFrom(value).buildPartial();
          } else {
            applicationAttemptId_ = value;
          }
          onChanged();
        } else {
          applicationAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getApplicationAttemptIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationAttemptIdFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
        if (applicationAttemptIdBuilder_ != null) {
          return applicationAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationAttemptId_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getApplicationAttemptIdFieldBuilder() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  applicationAttemptId_,
                  getParentForChildren(),
                  isClean());
          applicationAttemptId_ = null;
        }
        return applicationAttemptIdBuilder_;
      }
      
      // optional string diagnostics = 2;
      private java.lang.Object diagnostics_ = "";
      public boolean hasDiagnostics() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public String getDiagnostics() {
        java.lang.Object ref = diagnostics_;
        if (!(ref instanceof String)) {
          String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
          diagnostics_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      public Builder setDiagnostics(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        diagnostics_ = value;
        onChanged();
        return this;
      }
      public Builder clearDiagnostics() {
        bitField0_ = (bitField0_ & ~0x00000002);
        diagnostics_ = getDefaultInstance().getDiagnostics();
        onChanged();
        return this;
      }
      void setDiagnostics(com.google.protobuf.ByteString value) {
        bitField0_ |= 0x00000002;
        diagnostics_ = value;
        onChanged();
      }
      
      // optional string tracking_url = 3;
      private java.lang.Object trackingUrl_ = "";
      public boolean hasTrackingUrl() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public String getTrackingUrl() {
        java.lang.Object ref = trackingUrl_;
        if (!(ref instanceof String)) {
          String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
          trackingUrl_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      public Builder setTrackingUrl(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        trackingUrl_ = value;
        onChanged();
        return this;
      }
      public Builder clearTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00000004);
        trackingUrl_ = getDefaultInstance().getTrackingUrl();
        onChanged();
        return this;
      }
      void setTrackingUrl(com.google.protobuf.ByteString value) {
        bitField0_ |= 0x00000004;
        trackingUrl_ = value;
        onChanged();
      }
      
      // optional .FinalApplicationStatusProto final_application_status = 4;
      private org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto finalApplicationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED;
      public boolean hasFinalApplicationStatus() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus() {
        return finalApplicationStatus_;
      }
      public Builder setFinalApplicationStatus(org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        finalApplicationStatus_ = value;
        onChanged();
        return this;
      }
      public Builder clearFinalApplicationStatus() {
        bitField0_ = (bitField0_ & ~0x00000008);
        finalApplicationStatus_ = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:FinishApplicationMasterRequestProto)
    }
    
    static {
      defaultInstance = new FinishApplicationMasterRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:FinishApplicationMasterRequestProto)
  }
  
  public interface FinishApplicationMasterResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  public static final class FinishApplicationMasterResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements FinishApplicationMasterResponseProtoOrBuilder {
    // Use FinishApplicationMasterResponseProto.newBuilder() to construct.
    private FinishApplicationMasterResponseProto(Builder builder) {
      super(builder);
    }
    private FinishApplicationMasterResponseProto(boolean noInit) {}
    
    private static final FinishApplicationMasterResponseProto defaultInstance;
    public static FinishApplicationMasterResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public FinishApplicationMasterResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_FinishApplicationMasterResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_FinishApplicationMasterResponseProto_fieldAccessorTable;
    }
    
    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto) obj;
      
      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_FinishApplicationMasterResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_FinishApplicationMasterResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto(this);
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
          }
        }
      }
      
      
      // @@protoc_insertion_point(builder_scope:FinishApplicationMasterResponseProto)
    }
    
    static {
      defaultInstance = new FinishApplicationMasterResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:FinishApplicationMasterResponseProto)
  }
  
  public interface AllocateRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .ApplicationAttemptIdProto application_attempt_id = 1;
    boolean hasApplicationAttemptId();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder();
    
    // repeated .ResourceRequestProto ask = 2;
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> 
        getAskList();
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getAsk(int index);
    int getAskCount();
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
        getAskOrBuilderList();
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getAskOrBuilder(
        int index);
    
    // repeated .ContainerIdProto release = 3;
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> 
        getReleaseList();
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getRelease(int index);
    int getReleaseCount();
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getReleaseOrBuilderList();
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getReleaseOrBuilder(
        int index);
    
    // optional int32 response_id = 4;
    boolean hasResponseId();
    int getResponseId();
    
    // optional float progress = 5;
    boolean hasProgress();
    float getProgress();
  }
  public static final class AllocateRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements AllocateRequestProtoOrBuilder {
    // Use AllocateRequestProto.newBuilder() to construct.
    private AllocateRequestProto(Builder builder) {
      super(builder);
    }
    private AllocateRequestProto(boolean noInit) {}
    
    private static final AllocateRequestProto defaultInstance;
    public static AllocateRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public AllocateRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_AllocateRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_AllocateRequestProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .ApplicationAttemptIdProto application_attempt_id = 1;
    public static final int APPLICATION_ATTEMPT_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_;
    public boolean hasApplicationAttemptId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
      return applicationAttemptId_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
      return applicationAttemptId_;
    }
    
    // repeated .ResourceRequestProto ask = 2;
    public static final int ASK_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> ask_;
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> getAskList() {
      return ask_;
    }
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
        getAskOrBuilderList() {
      return ask_;
    }
    public int getAskCount() {
      return ask_.size();
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getAsk(int index) {
      return ask_.get(index);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getAskOrBuilder(
        int index) {
      return ask_.get(index);
    }
    
    // repeated .ContainerIdProto release = 3;
    public static final int RELEASE_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> release_;
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getReleaseList() {
      return release_;
    }
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
        getReleaseOrBuilderList() {
      return release_;
    }
    public int getReleaseCount() {
      return release_.size();
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getRelease(int index) {
      return release_.get(index);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getReleaseOrBuilder(
        int index) {
      return release_.get(index);
    }
    
    // optional int32 response_id = 4;
    public static final int RESPONSE_ID_FIELD_NUMBER = 4;
    private int responseId_;
    public boolean hasResponseId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public int getResponseId() {
      return responseId_;
    }
    
    // optional float progress = 5;
    public static final int PROGRESS_FIELD_NUMBER = 5;
    private float progress_;
    public boolean hasProgress() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public float getProgress() {
      return progress_;
    }
    
    private void initFields() {
      applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      ask_ = java.util.Collections.emptyList();
      release_ = java.util.Collections.emptyList();
      responseId_ = 0;
      progress_ = 0F;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationAttemptId_);
      }
      for (int i = 0; i < ask_.size(); i++) {
        output.writeMessage(2, ask_.get(i));
      }
      for (int i = 0; i < release_.size(); i++) {
        output.writeMessage(3, release_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(4, responseId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeFloat(5, progress_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationAttemptId_);
      }
      for (int i = 0; i < ask_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, ask_.get(i));
      }
      for (int i = 0; i < release_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, release_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, responseId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(5, progress_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto) obj;
      
      boolean result = true;
      result = result && (hasApplicationAttemptId() == other.hasApplicationAttemptId());
      if (hasApplicationAttemptId()) {
        result = result && getApplicationAttemptId()
            .equals(other.getApplicationAttemptId());
      }
      result = result && getAskList()
          .equals(other.getAskList());
      result = result && getReleaseList()
          .equals(other.getReleaseList());
      result = result && (hasResponseId() == other.hasResponseId());
      if (hasResponseId()) {
        result = result && (getResponseId()
            == other.getResponseId());
      }
      result = result && (hasProgress() == other.hasProgress());
      if (hasProgress()) {
        result = result && (Float.floatToIntBits(getProgress())    == Float.floatToIntBits(other.getProgress()));
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationAttemptId()) {
        hash = (37 * hash) + APPLICATION_ATTEMPT_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationAttemptId().hashCode();
      }
      if (getAskCount() > 0) {
        hash = (37 * hash) + ASK_FIELD_NUMBER;
        hash = (53 * hash) + getAskList().hashCode();
      }
      if (getReleaseCount() > 0) {
        hash = (37 * hash) + RELEASE_FIELD_NUMBER;
        hash = (53 * hash) + getReleaseList().hashCode();
      }
      if (hasResponseId()) {
        hash = (37 * hash) + RESPONSE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getResponseId();
      }
      if (hasProgress()) {
        hash = (37 * hash) + PROGRESS_FIELD_NUMBER;
        hash = (53 * hash) + Float.floatToIntBits(
            getProgress());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_AllocateRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_AllocateRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationAttemptIdFieldBuilder();
          getAskFieldBuilder();
          getReleaseFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (askBuilder_ == null) {
          ask_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          askBuilder_.clear();
        }
        if (releaseBuilder_ == null) {
          release_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          releaseBuilder_.clear();
        }
        responseId_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        progress_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationAttemptIdBuilder_ == null) {
          result.applicationAttemptId_ = applicationAttemptId_;
        } else {
          result.applicationAttemptId_ = applicationAttemptIdBuilder_.build();
        }
        if (askBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            ask_ = java.util.Collections.unmodifiableList(ask_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.ask_ = ask_;
        } else {
          result.ask_ = askBuilder_.build();
        }
        if (releaseBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            release_ = java.util.Collections.unmodifiableList(release_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.release_ = release_;
        } else {
          result.release_ = releaseBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000002;
        }
        result.responseId_ = responseId_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000004;
        }
        result.progress_ = progress_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationAttemptId()) {
          mergeApplicationAttemptId(other.getApplicationAttemptId());
        }
        if (askBuilder_ == null) {
          if (!other.ask_.isEmpty()) {
            if (ask_.isEmpty()) {
              ask_ = other.ask_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureAskIsMutable();
              ask_.addAll(other.ask_);
            }
            onChanged();
          }
        } else {
          if (!other.ask_.isEmpty()) {
            if (askBuilder_.isEmpty()) {
              askBuilder_.dispose();
              askBuilder_ = null;
              ask_ = other.ask_;
              bitField0_ = (bitField0_ & ~0x00000002);
              askBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAskFieldBuilder() : null;
            } else {
              askBuilder_.addAllMessages(other.ask_);
            }
          }
        }
        if (releaseBuilder_ == null) {
          if (!other.release_.isEmpty()) {
            if (release_.isEmpty()) {
              release_ = other.release_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureReleaseIsMutable();
              release_.addAll(other.release_);
            }
            onChanged();
          }
        } else {
          if (!other.release_.isEmpty()) {
            if (releaseBuilder_.isEmpty()) {
              releaseBuilder_.dispose();
              releaseBuilder_ = null;
              release_ = other.release_;
              bitField0_ = (bitField0_ & ~0x00000004);
              releaseBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getReleaseFieldBuilder() : null;
            } else {
              releaseBuilder_.addAllMessages(other.release_);
            }
          }
        }
        if (other.hasResponseId()) {
          setResponseId(other.getResponseId());
        }
        if (other.hasProgress()) {
          setProgress(other.getProgress());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder();
              if (hasApplicationAttemptId()) {
                subBuilder.mergeFrom(getApplicationAttemptId());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setApplicationAttemptId(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addAsk(subBuilder.buildPartial());
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addRelease(subBuilder.buildPartial());
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              responseId_ = input.readInt32();
              break;
            }
            case 45: {
              bitField0_ |= 0x00000010;
              progress_ = input.readFloat();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .ApplicationAttemptIdProto application_attempt_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> applicationAttemptIdBuilder_;
      public boolean hasApplicationAttemptId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          return applicationAttemptId_;
        } else {
          return applicationAttemptIdBuilder_.getMessage();
        }
      }
      public Builder setApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationAttemptId_ = value;
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setApplicationAttemptId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationAttemptId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            applicationAttemptId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(applicationAttemptId_).mergeFrom(value).buildPartial();
          } else {
            applicationAttemptId_ = value;
          }
          onChanged();
        } else {
          applicationAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getApplicationAttemptIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationAttemptIdFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
        if (applicationAttemptIdBuilder_ != null) {
          return applicationAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationAttemptId_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getApplicationAttemptIdFieldBuilder() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  applicationAttemptId_,
                  getParentForChildren(),
                  isClean());
          applicationAttemptId_ = null;
        }
        return applicationAttemptIdBuilder_;
      }
      
      // repeated .ResourceRequestProto ask = 2;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> ask_ =
        java.util.Collections.emptyList();
      private void ensureAskIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          ask_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto>(ask_);
          bitField0_ |= 0x00000002;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> askBuilder_;
      
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> getAskList() {
        if (askBuilder_ == null) {
          return java.util.Collections.unmodifiableList(ask_);
        } else {
          return askBuilder_.getMessageList();
        }
      }
      public int getAskCount() {
        if (askBuilder_ == null) {
          return ask_.size();
        } else {
          return askBuilder_.getCount();
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getAsk(int index) {
        if (askBuilder_ == null) {
          return ask_.get(index);
        } else {
          return askBuilder_.getMessage(index);
        }
      }
      public Builder setAsk(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (askBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAskIsMutable();
          ask_.set(index, value);
          onChanged();
        } else {
          askBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setAsk(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder builderForValue) {
        if (askBuilder_ == null) {
          ensureAskIsMutable();
          ask_.set(index, builderForValue.build());
          onChanged();
        } else {
          askBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAsk(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (askBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAskIsMutable();
          ask_.add(value);
          onChanged();
        } else {
          askBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addAsk(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (askBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAskIsMutable();
          ask_.add(index, value);
          onChanged();
        } else {
          askBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addAsk(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder builderForValue) {
        if (askBuilder_ == null) {
          ensureAskIsMutable();
          ask_.add(builderForValue.build());
          onChanged();
        } else {
          askBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addAsk(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder builderForValue) {
        if (askBuilder_ == null) {
          ensureAskIsMutable();
          ask_.add(index, builderForValue.build());
          onChanged();
        } else {
          askBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllAsk(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto> values) {
        if (askBuilder_ == null) {
          ensureAskIsMutable();
          super.addAll(values, ask_);
          onChanged();
        } else {
          askBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearAsk() {
        if (askBuilder_ == null) {
          ask_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          askBuilder_.clear();
        }
        return this;
      }
      public Builder removeAsk(int index) {
        if (askBuilder_ == null) {
          ensureAskIsMutable();
          ask_.remove(index);
          onChanged();
        } else {
          askBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder getAskBuilder(
          int index) {
        return getAskFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getAskOrBuilder(
          int index) {
        if (askBuilder_ == null) {
          return ask_.get(index);  } else {
          return askBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
           getAskOrBuilderList() {
        if (askBuilder_ != null) {
          return askBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(ask_);
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder addAskBuilder() {
        return getAskFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance());
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder addAskBuilder(
          int index) {
        return getAskFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder> 
           getAskBuilderList() {
        return getAskFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
          getAskFieldBuilder() {
        if (askBuilder_ == null) {
          askBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder>(
                  ask_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          ask_ = null;
        }
        return askBuilder_;
      }
      
      // repeated .ContainerIdProto release = 3;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> release_ =
        java.util.Collections.emptyList();
      private void ensureReleaseIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          release_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto>(release_);
          bitField0_ |= 0x00000004;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> releaseBuilder_;
      
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> getReleaseList() {
        if (releaseBuilder_ == null) {
          return java.util.Collections.unmodifiableList(release_);
        } else {
          return releaseBuilder_.getMessageList();
        }
      }
      public int getReleaseCount() {
        if (releaseBuilder_ == null) {
          return release_.size();
        } else {
          return releaseBuilder_.getCount();
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getRelease(int index) {
        if (releaseBuilder_ == null) {
          return release_.get(index);
        } else {
          return releaseBuilder_.getMessage(index);
        }
      }
      public Builder setRelease(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (releaseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReleaseIsMutable();
          release_.set(index, value);
          onChanged();
        } else {
          releaseBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setRelease(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (releaseBuilder_ == null) {
          ensureReleaseIsMutable();
          release_.set(index, builderForValue.build());
          onChanged();
        } else {
          releaseBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addRelease(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (releaseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReleaseIsMutable();
          release_.add(value);
          onChanged();
        } else {
          releaseBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addRelease(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (releaseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReleaseIsMutable();
          release_.add(index, value);
          onChanged();
        } else {
          releaseBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addRelease(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (releaseBuilder_ == null) {
          ensureReleaseIsMutable();
          release_.add(builderForValue.build());
          onChanged();
        } else {
          releaseBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addRelease(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (releaseBuilder_ == null) {
          ensureReleaseIsMutable();
          release_.add(index, builderForValue.build());
          onChanged();
        } else {
          releaseBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllRelease(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto> values) {
        if (releaseBuilder_ == null) {
          ensureReleaseIsMutable();
          super.addAll(values, release_);
          onChanged();
        } else {
          releaseBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearRelease() {
        if (releaseBuilder_ == null) {
          release_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          releaseBuilder_.clear();
        }
        return this;
      }
      public Builder removeRelease(int index) {
        if (releaseBuilder_ == null) {
          ensureReleaseIsMutable();
          release_.remove(index);
          onChanged();
        } else {
          releaseBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getReleaseBuilder(
          int index) {
        return getReleaseFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getReleaseOrBuilder(
          int index) {
        if (releaseBuilder_ == null) {
          return release_.get(index);  } else {
          return releaseBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
           getReleaseOrBuilderList() {
        if (releaseBuilder_ != null) {
          return releaseBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(release_);
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addReleaseBuilder() {
        return getReleaseFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder addReleaseBuilder(
          int index) {
        return getReleaseFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder> 
           getReleaseBuilderList() {
        return getReleaseFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getReleaseFieldBuilder() {
        if (releaseBuilder_ == null) {
          releaseBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  release_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          release_ = null;
        }
        return releaseBuilder_;
      }
      
      // optional int32 response_id = 4;
      private int responseId_ ;
      public boolean hasResponseId() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public int getResponseId() {
        return responseId_;
      }
      public Builder setResponseId(int value) {
        bitField0_ |= 0x00000008;
        responseId_ = value;
        onChanged();
        return this;
      }
      public Builder clearResponseId() {
        bitField0_ = (bitField0_ & ~0x00000008);
        responseId_ = 0;
        onChanged();
        return this;
      }
      
      // optional float progress = 5;
      private float progress_ ;
      public boolean hasProgress() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      public float getProgress() {
        return progress_;
      }
      public Builder setProgress(float value) {
        bitField0_ |= 0x00000010;
        progress_ = value;
        onChanged();
        return this;
      }
      public Builder clearProgress() {
        bitField0_ = (bitField0_ & ~0x00000010);
        progress_ = 0F;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:AllocateRequestProto)
    }
    
    static {
      defaultInstance = new AllocateRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:AllocateRequestProto)
  }
  
  public interface AllocateResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .AMResponseProto AM_response = 1;
    boolean hasAMResponse();
    org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto getAMResponse();
    org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProtoOrBuilder getAMResponseOrBuilder();
    
    // optional int32 num_cluster_nodes = 2;
    boolean hasNumClusterNodes();
    int getNumClusterNodes();
  }
  public static final class AllocateResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements AllocateResponseProtoOrBuilder {
    // Use AllocateResponseProto.newBuilder() to construct.
    private AllocateResponseProto(Builder builder) {
      super(builder);
    }
    private AllocateResponseProto(boolean noInit) {}
    
    private static final AllocateResponseProto defaultInstance;
    public static AllocateResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public AllocateResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_AllocateResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_AllocateResponseProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .AMResponseProto AM_response = 1;
    public static final int AM_RESPONSE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto aMResponse_;
    public boolean hasAMResponse() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto getAMResponse() {
      return aMResponse_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProtoOrBuilder getAMResponseOrBuilder() {
      return aMResponse_;
    }
    
    // optional int32 num_cluster_nodes = 2;
    public static final int NUM_CLUSTER_NODES_FIELD_NUMBER = 2;
    private int numClusterNodes_;
    public boolean hasNumClusterNodes() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public int getNumClusterNodes() {
      return numClusterNodes_;
    }
    
    private void initFields() {
      aMResponse_ = org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto.getDefaultInstance();
      numClusterNodes_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, aMResponse_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, numClusterNodes_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, aMResponse_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, numClusterNodes_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto) obj;
      
      boolean result = true;
      result = result && (hasAMResponse() == other.hasAMResponse());
      if (hasAMResponse()) {
        result = result && getAMResponse()
            .equals(other.getAMResponse());
      }
      result = result && (hasNumClusterNodes() == other.hasNumClusterNodes());
      if (hasNumClusterNodes()) {
        result = result && (getNumClusterNodes()
            == other.getNumClusterNodes());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasAMResponse()) {
        hash = (37 * hash) + AM_RESPONSE_FIELD_NUMBER;
        hash = (53 * hash) + getAMResponse().hashCode();
      }
      if (hasNumClusterNodes()) {
        hash = (37 * hash) + NUM_CLUSTER_NODES_FIELD_NUMBER;
        hash = (53 * hash) + getNumClusterNodes();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_AllocateResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_AllocateResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getAMResponseFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (aMResponseBuilder_ == null) {
          aMResponse_ = org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto.getDefaultInstance();
        } else {
          aMResponseBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        numClusterNodes_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (aMResponseBuilder_ == null) {
          result.aMResponse_ = aMResponse_;
        } else {
          result.aMResponse_ = aMResponseBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.numClusterNodes_ = numClusterNodes_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.getDefaultInstance()) return this;
        if (other.hasAMResponse()) {
          mergeAMResponse(other.getAMResponse());
        }
        if (other.hasNumClusterNodes()) {
          setNumClusterNodes(other.getNumClusterNodes());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto.newBuilder();
              if (hasAMResponse()) {
                subBuilder.mergeFrom(getAMResponse());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setAMResponse(subBuilder.buildPartial());
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              numClusterNodes_ = input.readInt32();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .AMResponseProto AM_response = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto aMResponse_ = org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto, org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProtoOrBuilder> aMResponseBuilder_;
      public boolean hasAMResponse() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto getAMResponse() {
        if (aMResponseBuilder_ == null) {
          return aMResponse_;
        } else {
          return aMResponseBuilder_.getMessage();
        }
      }
      public Builder setAMResponse(org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto value) {
        if (aMResponseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          aMResponse_ = value;
          onChanged();
        } else {
          aMResponseBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setAMResponse(
          org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto.Builder builderForValue) {
        if (aMResponseBuilder_ == null) {
          aMResponse_ = builderForValue.build();
          onChanged();
        } else {
          aMResponseBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeAMResponse(org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto value) {
        if (aMResponseBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              aMResponse_ != org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto.getDefaultInstance()) {
            aMResponse_ =
              org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto.newBuilder(aMResponse_).mergeFrom(value).buildPartial();
          } else {
            aMResponse_ = value;
          }
          onChanged();
        } else {
          aMResponseBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearAMResponse() {
        if (aMResponseBuilder_ == null) {
          aMResponse_ = org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto.getDefaultInstance();
          onChanged();
        } else {
          aMResponseBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto.Builder getAMResponseBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getAMResponseFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProtoOrBuilder getAMResponseOrBuilder() {
        if (aMResponseBuilder_ != null) {
          return aMResponseBuilder_.getMessageOrBuilder();
        } else {
          return aMResponse_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto, org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProtoOrBuilder> 
          getAMResponseFieldBuilder() {
        if (aMResponseBuilder_ == null) {
          aMResponseBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto, org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.AMResponseProtoOrBuilder>(
                  aMResponse_,
                  getParentForChildren(),
                  isClean());
          aMResponse_ = null;
        }
        return aMResponseBuilder_;
      }
      
      // optional int32 num_cluster_nodes = 2;
      private int numClusterNodes_ ;
      public boolean hasNumClusterNodes() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public int getNumClusterNodes() {
        return numClusterNodes_;
      }
      public Builder setNumClusterNodes(int value) {
        bitField0_ |= 0x00000002;
        numClusterNodes_ = value;
        onChanged();
        return this;
      }
      public Builder clearNumClusterNodes() {
        bitField0_ = (bitField0_ & ~0x00000002);
        numClusterNodes_ = 0;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:AllocateResponseProto)
    }
    
    static {
      defaultInstance = new AllocateResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:AllocateResponseProto)
  }
  
  public interface GetNewApplicationRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  public static final class GetNewApplicationRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements GetNewApplicationRequestProtoOrBuilder {
    // Use GetNewApplicationRequestProto.newBuilder() to construct.
    private GetNewApplicationRequestProto(Builder builder) {
      super(builder);
    }
    private GetNewApplicationRequestProto(boolean noInit) {}
    
    private static final GetNewApplicationRequestProto defaultInstance;
    public static GetNewApplicationRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetNewApplicationRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetNewApplicationRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetNewApplicationRequestProto_fieldAccessorTable;
    }
    
    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto) obj;
      
      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetNewApplicationRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetNewApplicationRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto(this);
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
          }
        }
      }
      
      
      // @@protoc_insertion_point(builder_scope:GetNewApplicationRequestProto)
    }
    
    static {
      defaultInstance = new GetNewApplicationRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetNewApplicationRequestProto)
  }
  
  public interface GetNewApplicationResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .ApplicationIdProto application_id = 1;
    boolean hasApplicationId();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();
    
    // optional .ResourceProto minimumCapability = 2;
    boolean hasMinimumCapability();
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMinimumCapability();
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMinimumCapabilityOrBuilder();
    
    // optional .ResourceProto maximumCapability = 3;
    boolean hasMaximumCapability();
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMaximumCapability();
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaximumCapabilityOrBuilder();
  }
  public static final class GetNewApplicationResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements GetNewApplicationResponseProtoOrBuilder {
    // Use GetNewApplicationResponseProto.newBuilder() to construct.
    private GetNewApplicationResponseProto(Builder builder) {
      super(builder);
    }
    private GetNewApplicationResponseProto(boolean noInit) {}
    
    private static final GetNewApplicationResponseProto defaultInstance;
    public static GetNewApplicationResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetNewApplicationResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetNewApplicationResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetNewApplicationResponseProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .ApplicationIdProto application_id = 1;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_;
    }
    
    // optional .ResourceProto minimumCapability = 2;
    public static final int MINIMUMCAPABILITY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto minimumCapability_;
    public boolean hasMinimumCapability() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMinimumCapability() {
      return minimumCapability_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMinimumCapabilityOrBuilder() {
      return minimumCapability_;
    }
    
    // optional .ResourceProto maximumCapability = 3;
    public static final int MAXIMUMCAPABILITY_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto maximumCapability_;
    public boolean hasMaximumCapability() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMaximumCapability() {
      return maximumCapability_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaximumCapabilityOrBuilder() {
      return maximumCapability_;
    }
    
    private void initFields() {
      applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      minimumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      maximumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, minimumCapability_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, maximumCapability_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, minimumCapability_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, maximumCapability_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto) obj;
      
      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasMinimumCapability() == other.hasMinimumCapability());
      if (hasMinimumCapability()) {
        result = result && getMinimumCapability()
            .equals(other.getMinimumCapability());
      }
      result = result && (hasMaximumCapability() == other.hasMaximumCapability());
      if (hasMaximumCapability()) {
        result = result && getMaximumCapability()
            .equals(other.getMaximumCapability());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasMinimumCapability()) {
        hash = (37 * hash) + MINIMUMCAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getMinimumCapability().hashCode();
      }
      if (hasMaximumCapability()) {
        hash = (37 * hash) + MAXIMUMCAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getMaximumCapability().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetNewApplicationResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetNewApplicationResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
          getMinimumCapabilityFieldBuilder();
          getMaximumCapabilityFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (minimumCapabilityBuilder_ == null) {
          minimumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          minimumCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (maximumCapabilityBuilder_ == null) {
          maximumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
        } else {
          maximumCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (minimumCapabilityBuilder_ == null) {
          result.minimumCapability_ = minimumCapability_;
        } else {
          result.minimumCapability_ = minimumCapabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (maximumCapabilityBuilder_ == null) {
          result.maximumCapability_ = maximumCapability_;
        } else {
          result.maximumCapability_ = maximumCapabilityBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasMinimumCapability()) {
          mergeMinimumCapability(other.getMinimumCapability());
        }
        if (other.hasMaximumCapability()) {
          mergeMaximumCapability(other.getMaximumCapability());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder();
              if (hasApplicationId()) {
                subBuilder.mergeFrom(getApplicationId());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setApplicationId(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder();
              if (hasMinimumCapability()) {
                subBuilder.mergeFrom(getMinimumCapability());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setMinimumCapability(subBuilder.buildPartial());
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder();
              if (hasMaximumCapability()) {
                subBuilder.mergeFrom(getMaximumCapability());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setMaximumCapability(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .ApplicationIdProto application_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      public Builder setApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setApplicationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  applicationId_,
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }
      
      // optional .ResourceProto minimumCapability = 2;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto minimumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> minimumCapabilityBuilder_;
      public boolean hasMinimumCapability() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMinimumCapability() {
        if (minimumCapabilityBuilder_ == null) {
          return minimumCapability_;
        } else {
          return minimumCapabilityBuilder_.getMessage();
        }
      }
      public Builder setMinimumCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (minimumCapabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          minimumCapability_ = value;
          onChanged();
        } else {
          minimumCapabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setMinimumCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (minimumCapabilityBuilder_ == null) {
          minimumCapability_ = builderForValue.build();
          onChanged();
        } else {
          minimumCapabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeMinimumCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (minimumCapabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              minimumCapability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            minimumCapability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(minimumCapability_).mergeFrom(value).buildPartial();
          } else {
            minimumCapability_ = value;
          }
          onChanged();
        } else {
          minimumCapabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearMinimumCapability() {
        if (minimumCapabilityBuilder_ == null) {
          minimumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          minimumCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getMinimumCapabilityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getMinimumCapabilityFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMinimumCapabilityOrBuilder() {
        if (minimumCapabilityBuilder_ != null) {
          return minimumCapabilityBuilder_.getMessageOrBuilder();
        } else {
          return minimumCapability_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getMinimumCapabilityFieldBuilder() {
        if (minimumCapabilityBuilder_ == null) {
          minimumCapabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  minimumCapability_,
                  getParentForChildren(),
                  isClean());
          minimumCapability_ = null;
        }
        return minimumCapabilityBuilder_;
      }
      
      // optional .ResourceProto maximumCapability = 3;
      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto maximumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> maximumCapabilityBuilder_;
      public boolean hasMaximumCapability() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getMaximumCapability() {
        if (maximumCapabilityBuilder_ == null) {
          return maximumCapability_;
        } else {
          return maximumCapabilityBuilder_.getMessage();
        }
      }
      public Builder setMaximumCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (maximumCapabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          maximumCapability_ = value;
          onChanged();
        } else {
          maximumCapabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      public Builder setMaximumCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (maximumCapabilityBuilder_ == null) {
          maximumCapability_ = builderForValue.build();
          onChanged();
        } else {
          maximumCapabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      public Builder mergeMaximumCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (maximumCapabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              maximumCapability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            maximumCapability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(maximumCapability_).mergeFrom(value).buildPartial();
          } else {
            maximumCapability_ = value;
          }
          onChanged();
        } else {
          maximumCapabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      public Builder clearMaximumCapability() {
        if (maximumCapabilityBuilder_ == null) {
          maximumCapability_ = org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
          onChanged();
        } else {
          maximumCapabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getMaximumCapabilityBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getMaximumCapabilityFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getMaximumCapabilityOrBuilder() {
        if (maximumCapabilityBuilder_ != null) {
          return maximumCapabilityBuilder_.getMessageOrBuilder();
        } else {
          return maximumCapability_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getMaximumCapabilityFieldBuilder() {
        if (maximumCapabilityBuilder_ == null) {
          maximumCapabilityBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  maximumCapability_,
                  getParentForChildren(),
                  isClean());
          maximumCapability_ = null;
        }
        return maximumCapabilityBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:GetNewApplicationResponseProto)
    }
    
    static {
      defaultInstance = new GetNewApplicationResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetNewApplicationResponseProto)
  }
  
  public interface GetApplicationReportRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .ApplicationIdProto application_id = 1;
    boolean hasApplicationId();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();
  }
  public static final class GetApplicationReportRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements GetApplicationReportRequestProtoOrBuilder {
    // Use GetApplicationReportRequestProto.newBuilder() to construct.
    private GetApplicationReportRequestProto(Builder builder) {
      super(builder);
    }
    private GetApplicationReportRequestProto(boolean noInit) {}
    
    private static final GetApplicationReportRequestProto defaultInstance;
    public static GetApplicationReportRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetApplicationReportRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetApplicationReportRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetApplicationReportRequestProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .ApplicationIdProto application_id = 1;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_;
    }
    
    private void initFields() {
      applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationId_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto) obj;
      
      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetApplicationReportRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetApplicationReportRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder();
              if (hasApplicationId()) {
                subBuilder.mergeFrom(getApplicationId());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setApplicationId(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .ApplicationIdProto application_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      public Builder setApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setApplicationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  applicationId_,
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:GetApplicationReportRequestProto)
    }
    
    static {
      defaultInstance = new GetApplicationReportRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetApplicationReportRequestProto)
  }
  
  public interface GetApplicationReportResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .ApplicationReportProto application_report = 1;
    boolean hasApplicationReport();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplicationReport();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationReportOrBuilder();
  }
  public static final class GetApplicationReportResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements GetApplicationReportResponseProtoOrBuilder {
    // Use GetApplicationReportResponseProto.newBuilder() to construct.
    private GetApplicationReportResponseProto(Builder builder) {
      super(builder);
    }
    private GetApplicationReportResponseProto(boolean noInit) {}
    
    private static final GetApplicationReportResponseProto defaultInstance;
    public static GetApplicationReportResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetApplicationReportResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetApplicationReportResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetApplicationReportResponseProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .ApplicationReportProto application_report = 1;
    public static final int APPLICATION_REPORT_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto applicationReport_;
    public boolean hasApplicationReport() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplicationReport() {
      return applicationReport_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationReportOrBuilder() {
      return applicationReport_;
    }
    
    private void initFields() {
      applicationReport_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationReport_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationReport_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto) obj;
      
      boolean result = true;
      result = result && (hasApplicationReport() == other.hasApplicationReport());
      if (hasApplicationReport()) {
        result = result && getApplicationReport()
            .equals(other.getApplicationReport());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationReport()) {
        hash = (37 * hash) + APPLICATION_REPORT_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationReport().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetApplicationReportResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetApplicationReportResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationReportFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (applicationReportBuilder_ == null) {
          applicationReport_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance();
        } else {
          applicationReportBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationReportBuilder_ == null) {
          result.applicationReport_ = applicationReport_;
        } else {
          result.applicationReport_ = applicationReportBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto.getDefaultInstance()) return this;
        if (other.hasApplicationReport()) {
          mergeApplicationReport(other.getApplicationReport());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.newBuilder();
              if (hasApplicationReport()) {
                subBuilder.mergeFrom(getApplicationReport());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setApplicationReport(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .ApplicationReportProto application_report = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto applicationReport_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> applicationReportBuilder_;
      public boolean hasApplicationReport() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplicationReport() {
        if (applicationReportBuilder_ == null) {
          return applicationReport_;
        } else {
          return applicationReportBuilder_.getMessage();
        }
      }
      public Builder setApplicationReport(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationReportBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationReport_ = value;
          onChanged();
        } else {
          applicationReportBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setApplicationReport(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationReportBuilder_ == null) {
          applicationReport_ = builderForValue.build();
          onChanged();
        } else {
          applicationReportBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeApplicationReport(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationReportBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationReport_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance()) {
            applicationReport_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.newBuilder(applicationReport_).mergeFrom(value).buildPartial();
          } else {
            applicationReport_ = value;
          }
          onChanged();
        } else {
          applicationReportBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearApplicationReport() {
        if (applicationReportBuilder_ == null) {
          applicationReport_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance();
          onChanged();
        } else {
          applicationReportBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder getApplicationReportBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationReportFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationReportOrBuilder() {
        if (applicationReportBuilder_ != null) {
          return applicationReportBuilder_.getMessageOrBuilder();
        } else {
          return applicationReport_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
          getApplicationReportFieldBuilder() {
        if (applicationReportBuilder_ == null) {
          applicationReportBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder>(
                  applicationReport_,
                  getParentForChildren(),
                  isClean());
          applicationReport_ = null;
        }
        return applicationReportBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:GetApplicationReportResponseProto)
    }
    
    static {
      defaultInstance = new GetApplicationReportResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetApplicationReportResponseProto)
  }
  
  public interface SubmitApplicationRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .ApplicationSubmissionContextProto application_submission_context = 1;
    boolean hasApplicationSubmissionContext();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto getApplicationSubmissionContext();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder getApplicationSubmissionContextOrBuilder();
  }
  public static final class SubmitApplicationRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements SubmitApplicationRequestProtoOrBuilder {
    // Use SubmitApplicationRequestProto.newBuilder() to construct.
    private SubmitApplicationRequestProto(Builder builder) {
      super(builder);
    }
    private SubmitApplicationRequestProto(boolean noInit) {}
    
    private static final SubmitApplicationRequestProto defaultInstance;
    public static SubmitApplicationRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public SubmitApplicationRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_SubmitApplicationRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_SubmitApplicationRequestProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .ApplicationSubmissionContextProto application_submission_context = 1;
    public static final int APPLICATION_SUBMISSION_CONTEXT_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto applicationSubmissionContext_;
    public boolean hasApplicationSubmissionContext() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto getApplicationSubmissionContext() {
      return applicationSubmissionContext_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder getApplicationSubmissionContextOrBuilder() {
      return applicationSubmissionContext_;
    }
    
    private void initFields() {
      applicationSubmissionContext_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationSubmissionContext_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationSubmissionContext_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto) obj;
      
      boolean result = true;
      result = result && (hasApplicationSubmissionContext() == other.hasApplicationSubmissionContext());
      if (hasApplicationSubmissionContext()) {
        result = result && getApplicationSubmissionContext()
            .equals(other.getApplicationSubmissionContext());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationSubmissionContext()) {
        hash = (37 * hash) + APPLICATION_SUBMISSION_CONTEXT_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationSubmissionContext().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_SubmitApplicationRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_SubmitApplicationRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationSubmissionContextFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (applicationSubmissionContextBuilder_ == null) {
          applicationSubmissionContext_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance();
        } else {
          applicationSubmissionContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationSubmissionContextBuilder_ == null) {
          result.applicationSubmissionContext_ = applicationSubmissionContext_;
        } else {
          result.applicationSubmissionContext_ = applicationSubmissionContextBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationSubmissionContext()) {
          mergeApplicationSubmissionContext(other.getApplicationSubmissionContext());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.newBuilder();
              if (hasApplicationSubmissionContext()) {
                subBuilder.mergeFrom(getApplicationSubmissionContext());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setApplicationSubmissionContext(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .ApplicationSubmissionContextProto application_submission_context = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto applicationSubmissionContext_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder> applicationSubmissionContextBuilder_;
      public boolean hasApplicationSubmissionContext() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto getApplicationSubmissionContext() {
        if (applicationSubmissionContextBuilder_ == null) {
          return applicationSubmissionContext_;
        } else {
          return applicationSubmissionContextBuilder_.getMessage();
        }
      }
      public Builder setApplicationSubmissionContext(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto value) {
        if (applicationSubmissionContextBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationSubmissionContext_ = value;
          onChanged();
        } else {
          applicationSubmissionContextBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setApplicationSubmissionContext(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder builderForValue) {
        if (applicationSubmissionContextBuilder_ == null) {
          applicationSubmissionContext_ = builderForValue.build();
          onChanged();
        } else {
          applicationSubmissionContextBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeApplicationSubmissionContext(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto value) {
        if (applicationSubmissionContextBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationSubmissionContext_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance()) {
            applicationSubmissionContext_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.newBuilder(applicationSubmissionContext_).mergeFrom(value).buildPartial();
          } else {
            applicationSubmissionContext_ = value;
          }
          onChanged();
        } else {
          applicationSubmissionContextBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearApplicationSubmissionContext() {
        if (applicationSubmissionContextBuilder_ == null) {
          applicationSubmissionContext_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance();
          onChanged();
        } else {
          applicationSubmissionContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder getApplicationSubmissionContextBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationSubmissionContextFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder getApplicationSubmissionContextOrBuilder() {
        if (applicationSubmissionContextBuilder_ != null) {
          return applicationSubmissionContextBuilder_.getMessageOrBuilder();
        } else {
          return applicationSubmissionContext_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder> 
          getApplicationSubmissionContextFieldBuilder() {
        if (applicationSubmissionContextBuilder_ == null) {
          applicationSubmissionContextBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder>(
                  applicationSubmissionContext_,
                  getParentForChildren(),
                  isClean());
          applicationSubmissionContext_ = null;
        }
        return applicationSubmissionContextBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:SubmitApplicationRequestProto)
    }
    
    static {
      defaultInstance = new SubmitApplicationRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:SubmitApplicationRequestProto)
  }
  
  public interface SubmitApplicationResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  public static final class SubmitApplicationResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements SubmitApplicationResponseProtoOrBuilder {
    // Use SubmitApplicationResponseProto.newBuilder() to construct.
    private SubmitApplicationResponseProto(Builder builder) {
      super(builder);
    }
    private SubmitApplicationResponseProto(boolean noInit) {}
    
    private static final SubmitApplicationResponseProto defaultInstance;
    public static SubmitApplicationResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public SubmitApplicationResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_SubmitApplicationResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_SubmitApplicationResponseProto_fieldAccessorTable;
    }
    
    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto) obj;
      
      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_SubmitApplicationResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_SubmitApplicationResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto(this);
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
          }
        }
      }
      
      
      // @@protoc_insertion_point(builder_scope:SubmitApplicationResponseProto)
    }
    
    static {
      defaultInstance = new SubmitApplicationResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:SubmitApplicationResponseProto)
  }
  
  public interface KillApplicationRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .ApplicationIdProto application_id = 1;
    boolean hasApplicationId();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();
  }
  public static final class KillApplicationRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements KillApplicationRequestProtoOrBuilder {
    // Use KillApplicationRequestProto.newBuilder() to construct.
    private KillApplicationRequestProto(Builder builder) {
      super(builder);
    }
    private KillApplicationRequestProto(boolean noInit) {}
    
    private static final KillApplicationRequestProto defaultInstance;
    public static KillApplicationRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public KillApplicationRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_KillApplicationRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_KillApplicationRequestProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .ApplicationIdProto application_id = 1;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_;
    }
    
    private void initFields() {
      applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationId_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto) obj;
      
      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_KillApplicationRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_KillApplicationRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder();
              if (hasApplicationId()) {
                subBuilder.mergeFrom(getApplicationId());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setApplicationId(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .ApplicationIdProto application_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      public Builder setApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setApplicationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  applicationId_,
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:KillApplicationRequestProto)
    }
    
    static {
      defaultInstance = new KillApplicationRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:KillApplicationRequestProto)
  }
  
  public interface KillApplicationResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  public static final class KillApplicationResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements KillApplicationResponseProtoOrBuilder {
    // Use KillApplicationResponseProto.newBuilder() to construct.
    private KillApplicationResponseProto(Builder builder) {
      super(builder);
    }
    private KillApplicationResponseProto(boolean noInit) {}
    
    private static final KillApplicationResponseProto defaultInstance;
    public static KillApplicationResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public KillApplicationResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_KillApplicationResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_KillApplicationResponseProto_fieldAccessorTable;
    }
    
    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto) obj;
      
      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_KillApplicationResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_KillApplicationResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto(this);
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
          }
        }
      }
      
      
      // @@protoc_insertion_point(builder_scope:KillApplicationResponseProto)
    }
    
    static {
      defaultInstance = new KillApplicationResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:KillApplicationResponseProto)
  }
  
  public interface GetClusterMetricsRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  public static final class GetClusterMetricsRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements GetClusterMetricsRequestProtoOrBuilder {
    // Use GetClusterMetricsRequestProto.newBuilder() to construct.
    private GetClusterMetricsRequestProto(Builder builder) {
      super(builder);
    }
    private GetClusterMetricsRequestProto(boolean noInit) {}
    
    private static final GetClusterMetricsRequestProto defaultInstance;
    public static GetClusterMetricsRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetClusterMetricsRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterMetricsRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterMetricsRequestProto_fieldAccessorTable;
    }
    
    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto) obj;
      
      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterMetricsRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterMetricsRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto(this);
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
          }
        }
      }
      
      
      // @@protoc_insertion_point(builder_scope:GetClusterMetricsRequestProto)
    }
    
    static {
      defaultInstance = new GetClusterMetricsRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetClusterMetricsRequestProto)
  }
  
  public interface GetClusterMetricsResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .YarnClusterMetricsProto cluster_metrics = 1;
    boolean hasClusterMetrics();
    org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto getClusterMetrics();
    org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder getClusterMetricsOrBuilder();
  }
  public static final class GetClusterMetricsResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements GetClusterMetricsResponseProtoOrBuilder {
    // Use GetClusterMetricsResponseProto.newBuilder() to construct.
    private GetClusterMetricsResponseProto(Builder builder) {
      super(builder);
    }
    private GetClusterMetricsResponseProto(boolean noInit) {}
    
    private static final GetClusterMetricsResponseProto defaultInstance;
    public static GetClusterMetricsResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetClusterMetricsResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterMetricsResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterMetricsResponseProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .YarnClusterMetricsProto cluster_metrics = 1;
    public static final int CLUSTER_METRICS_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto clusterMetrics_;
    public boolean hasClusterMetrics() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto getClusterMetrics() {
      return clusterMetrics_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder getClusterMetricsOrBuilder() {
      return clusterMetrics_;
    }
    
    private void initFields() {
      clusterMetrics_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, clusterMetrics_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, clusterMetrics_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto) obj;
      
      boolean result = true;
      result = result && (hasClusterMetrics() == other.hasClusterMetrics());
      if (hasClusterMetrics()) {
        result = result && getClusterMetrics()
            .equals(other.getClusterMetrics());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasClusterMetrics()) {
        hash = (37 * hash) + CLUSTER_METRICS_FIELD_NUMBER;
        hash = (53 * hash) + getClusterMetrics().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterMetricsResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterMetricsResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getClusterMetricsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (clusterMetricsBuilder_ == null) {
          clusterMetrics_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance();
        } else {
          clusterMetricsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (clusterMetricsBuilder_ == null) {
          result.clusterMetrics_ = clusterMetrics_;
        } else {
          result.clusterMetrics_ = clusterMetricsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto.getDefaultInstance()) return this;
        if (other.hasClusterMetrics()) {
          mergeClusterMetrics(other.getClusterMetrics());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.newBuilder();
              if (hasClusterMetrics()) {
                subBuilder.mergeFrom(getClusterMetrics());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setClusterMetrics(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .YarnClusterMetricsProto cluster_metrics = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto clusterMetrics_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto, org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder> clusterMetricsBuilder_;
      public boolean hasClusterMetrics() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto getClusterMetrics() {
        if (clusterMetricsBuilder_ == null) {
          return clusterMetrics_;
        } else {
          return clusterMetricsBuilder_.getMessage();
        }
      }
      public Builder setClusterMetrics(org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto value) {
        if (clusterMetricsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          clusterMetrics_ = value;
          onChanged();
        } else {
          clusterMetricsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setClusterMetrics(
          org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder builderForValue) {
        if (clusterMetricsBuilder_ == null) {
          clusterMetrics_ = builderForValue.build();
          onChanged();
        } else {
          clusterMetricsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeClusterMetrics(org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto value) {
        if (clusterMetricsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              clusterMetrics_ != org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance()) {
            clusterMetrics_ =
              org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.newBuilder(clusterMetrics_).mergeFrom(value).buildPartial();
          } else {
            clusterMetrics_ = value;
          }
          onChanged();
        } else {
          clusterMetricsBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearClusterMetrics() {
        if (clusterMetricsBuilder_ == null) {
          clusterMetrics_ = org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance();
          onChanged();
        } else {
          clusterMetricsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder getClusterMetricsBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getClusterMetricsFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder getClusterMetricsOrBuilder() {
        if (clusterMetricsBuilder_ != null) {
          return clusterMetricsBuilder_.getMessageOrBuilder();
        } else {
          return clusterMetrics_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto, org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder> 
          getClusterMetricsFieldBuilder() {
        if (clusterMetricsBuilder_ == null) {
          clusterMetricsBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto, org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder>(
                  clusterMetrics_,
                  getParentForChildren(),
                  isClean());
          clusterMetrics_ = null;
        }
        return clusterMetricsBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:GetClusterMetricsResponseProto)
    }
    
    static {
      defaultInstance = new GetClusterMetricsResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetClusterMetricsResponseProto)
  }
  
  public interface GetAllApplicationsRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  public static final class GetAllApplicationsRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements GetAllApplicationsRequestProtoOrBuilder {
    // Use GetAllApplicationsRequestProto.newBuilder() to construct.
    private GetAllApplicationsRequestProto(Builder builder) {
      super(builder);
    }
    private GetAllApplicationsRequestProto(boolean noInit) {}
    
    private static final GetAllApplicationsRequestProto defaultInstance;
    public static GetAllApplicationsRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetAllApplicationsRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetAllApplicationsRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetAllApplicationsRequestProto_fieldAccessorTable;
    }
    
    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto) obj;
      
      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetAllApplicationsRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetAllApplicationsRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto(this);
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
          }
        }
      }
      
      
      // @@protoc_insertion_point(builder_scope:GetAllApplicationsRequestProto)
    }
    
    static {
      defaultInstance = new GetAllApplicationsRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetAllApplicationsRequestProto)
  }
  
  public interface GetAllApplicationsResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // repeated .ApplicationReportProto applications = 1;
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> 
        getApplicationsList();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index);
    int getApplicationsCount();
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
        getApplicationsOrBuilderList();
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
        int index);
  }
  public static final class GetAllApplicationsResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements GetAllApplicationsResponseProtoOrBuilder {
    // Use GetAllApplicationsResponseProto.newBuilder() to construct.
    private GetAllApplicationsResponseProto(Builder builder) {
      super(builder);
    }
    private GetAllApplicationsResponseProto(boolean noInit) {}
    
    private static final GetAllApplicationsResponseProto defaultInstance;
    public static GetAllApplicationsResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetAllApplicationsResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetAllApplicationsResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetAllApplicationsResponseProto_fieldAccessorTable;
    }
    
    // repeated .ApplicationReportProto applications = 1;
    public static final int APPLICATIONS_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> applications_;
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> getApplicationsList() {
      return applications_;
    }
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
        getApplicationsOrBuilderList() {
      return applications_;
    }
    public int getApplicationsCount() {
      return applications_.size();
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index) {
      return applications_.get(index);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
        int index) {
      return applications_.get(index);
    }
    
    private void initFields() {
      applications_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < applications_.size(); i++) {
        output.writeMessage(1, applications_.get(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      for (int i = 0; i < applications_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applications_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto) obj;
      
      boolean result = true;
      result = result && getApplicationsList()
          .equals(other.getApplicationsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getApplicationsCount() > 0) {
        hash = (37 * hash) + APPLICATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetAllApplicationsResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetAllApplicationsResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (applicationsBuilder_ == null) {
          applications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          applicationsBuilder_.clear();
        }
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (applicationsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            applications_ = java.util.Collections.unmodifiableList(applications_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.applications_ = applications_;
        } else {
          result.applications_ = applicationsBuilder_.build();
        }
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto.getDefaultInstance()) return this;
        if (applicationsBuilder_ == null) {
          if (!other.applications_.isEmpty()) {
            if (applications_.isEmpty()) {
              applications_ = other.applications_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureApplicationsIsMutable();
              applications_.addAll(other.applications_);
            }
            onChanged();
          }
        } else {
          if (!other.applications_.isEmpty()) {
            if (applicationsBuilder_.isEmpty()) {
              applicationsBuilder_.dispose();
              applicationsBuilder_ = null;
              applications_ = other.applications_;
              bitField0_ = (bitField0_ & ~0x00000001);
              applicationsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getApplicationsFieldBuilder() : null;
            } else {
              applicationsBuilder_.addAllMessages(other.applications_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addApplications(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // repeated .ApplicationReportProto applications = 1;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> applications_ =
        java.util.Collections.emptyList();
      private void ensureApplicationsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          applications_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto>(applications_);
          bitField0_ |= 0x00000001;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> applicationsBuilder_;
      
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> getApplicationsList() {
        if (applicationsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applications_);
        } else {
          return applicationsBuilder_.getMessageList();
        }
      }
      public int getApplicationsCount() {
        if (applicationsBuilder_ == null) {
          return applications_.size();
        } else {
          return applicationsBuilder_.getCount();
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index) {
        if (applicationsBuilder_ == null) {
          return applications_.get(index);
        } else {
          return applicationsBuilder_.getMessage(index);
        }
      }
      public Builder setApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.set(index, value);
          onChanged();
        } else {
          applicationsBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addApplications(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.add(value);
          onChanged();
        } else {
          applicationsBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.add(index, value);
          onChanged();
        } else {
          applicationsBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addApplications(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.add(builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllApplications(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> values) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          super.addAll(values, applications_);
          onChanged();
        } else {
          applicationsBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearApplications() {
        if (applicationsBuilder_ == null) {
          applications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          applicationsBuilder_.clear();
        }
        return this;
      }
      public Builder removeApplications(int index) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.remove(index);
          onChanged();
        } else {
          applicationsBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder getApplicationsBuilder(
          int index) {
        return getApplicationsFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
          int index) {
        if (applicationsBuilder_ == null) {
          return applications_.get(index);  } else {
          return applicationsBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
           getApplicationsOrBuilderList() {
        if (applicationsBuilder_ != null) {
          return applicationsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applications_);
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder addApplicationsBuilder() {
        return getApplicationsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance());
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder addApplicationsBuilder(
          int index) {
        return getApplicationsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder> 
           getApplicationsBuilderList() {
        return getApplicationsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
          getApplicationsFieldBuilder() {
        if (applicationsBuilder_ == null) {
          applicationsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder>(
                  applications_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          applications_ = null;
        }
        return applicationsBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:GetAllApplicationsResponseProto)
    }
    
    static {
      defaultInstance = new GetAllApplicationsResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetAllApplicationsResponseProto)
  }
  
  public interface GetClusterNodesRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  public static final class GetClusterNodesRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements GetClusterNodesRequestProtoOrBuilder {
    // Use GetClusterNodesRequestProto.newBuilder() to construct.
    private GetClusterNodesRequestProto(Builder builder) {
      super(builder);
    }
    private GetClusterNodesRequestProto(boolean noInit) {}
    
    private static final GetClusterNodesRequestProto defaultInstance;
    public static GetClusterNodesRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetClusterNodesRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterNodesRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterNodesRequestProto_fieldAccessorTable;
    }
    
    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto) obj;
      
      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterNodesRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterNodesRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto(this);
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
          }
        }
      }
      
      
      // @@protoc_insertion_point(builder_scope:GetClusterNodesRequestProto)
    }
    
    static {
      defaultInstance = new GetClusterNodesRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetClusterNodesRequestProto)
  }
  
  public interface GetClusterNodesResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // repeated .NodeReportProto nodeReports = 1;
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto> 
        getNodeReportsList();
    org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto getNodeReports(int index);
    int getNodeReportsCount();
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> 
        getNodeReportsOrBuilderList();
    org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder getNodeReportsOrBuilder(
        int index);
  }
  public static final class GetClusterNodesResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements GetClusterNodesResponseProtoOrBuilder {
    // Use GetClusterNodesResponseProto.newBuilder() to construct.
    private GetClusterNodesResponseProto(Builder builder) {
      super(builder);
    }
    private GetClusterNodesResponseProto(boolean noInit) {}
    
    private static final GetClusterNodesResponseProto defaultInstance;
    public static GetClusterNodesResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetClusterNodesResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterNodesResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterNodesResponseProto_fieldAccessorTable;
    }
    
    // repeated .NodeReportProto nodeReports = 1;
    public static final int NODEREPORTS_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto> nodeReports_;
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto> getNodeReportsList() {
      return nodeReports_;
    }
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> 
        getNodeReportsOrBuilderList() {
      return nodeReports_;
    }
    public int getNodeReportsCount() {
      return nodeReports_.size();
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto getNodeReports(int index) {
      return nodeReports_.get(index);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder getNodeReportsOrBuilder(
        int index) {
      return nodeReports_.get(index);
    }
    
    private void initFields() {
      nodeReports_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < nodeReports_.size(); i++) {
        output.writeMessage(1, nodeReports_.get(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      for (int i = 0; i < nodeReports_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, nodeReports_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto) obj;
      
      boolean result = true;
      result = result && getNodeReportsList()
          .equals(other.getNodeReportsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getNodeReportsCount() > 0) {
        hash = (37 * hash) + NODEREPORTS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeReportsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterNodesResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetClusterNodesResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getNodeReportsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (nodeReportsBuilder_ == null) {
          nodeReports_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          nodeReportsBuilder_.clear();
        }
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (nodeReportsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            nodeReports_ = java.util.Collections.unmodifiableList(nodeReports_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.nodeReports_ = nodeReports_;
        } else {
          result.nodeReports_ = nodeReportsBuilder_.build();
        }
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto.getDefaultInstance()) return this;
        if (nodeReportsBuilder_ == null) {
          if (!other.nodeReports_.isEmpty()) {
            if (nodeReports_.isEmpty()) {
              nodeReports_ = other.nodeReports_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureNodeReportsIsMutable();
              nodeReports_.addAll(other.nodeReports_);
            }
            onChanged();
          }
        } else {
          if (!other.nodeReports_.isEmpty()) {
            if (nodeReportsBuilder_.isEmpty()) {
              nodeReportsBuilder_.dispose();
              nodeReportsBuilder_ = null;
              nodeReports_ = other.nodeReports_;
              bitField0_ = (bitField0_ & ~0x00000001);
              nodeReportsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getNodeReportsFieldBuilder() : null;
            } else {
              nodeReportsBuilder_.addAllMessages(other.nodeReports_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addNodeReports(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // repeated .NodeReportProto nodeReports = 1;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto> nodeReports_ =
        java.util.Collections.emptyList();
      private void ensureNodeReportsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          nodeReports_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto>(nodeReports_);
          bitField0_ |= 0x00000001;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> nodeReportsBuilder_;
      
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto> getNodeReportsList() {
        if (nodeReportsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(nodeReports_);
        } else {
          return nodeReportsBuilder_.getMessageList();
        }
      }
      public int getNodeReportsCount() {
        if (nodeReportsBuilder_ == null) {
          return nodeReports_.size();
        } else {
          return nodeReportsBuilder_.getCount();
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto getNodeReports(int index) {
        if (nodeReportsBuilder_ == null) {
          return nodeReports_.get(index);
        } else {
          return nodeReportsBuilder_.getMessage(index);
        }
      }
      public Builder setNodeReports(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto value) {
        if (nodeReportsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeReportsIsMutable();
          nodeReports_.set(index, value);
          onChanged();
        } else {
          nodeReportsBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setNodeReports(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder builderForValue) {
        if (nodeReportsBuilder_ == null) {
          ensureNodeReportsIsMutable();
          nodeReports_.set(index, builderForValue.build());
          onChanged();
        } else {
          nodeReportsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addNodeReports(org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto value) {
        if (nodeReportsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeReportsIsMutable();
          nodeReports_.add(value);
          onChanged();
        } else {
          nodeReportsBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addNodeReports(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto value) {
        if (nodeReportsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureNodeReportsIsMutable();
          nodeReports_.add(index, value);
          onChanged();
        } else {
          nodeReportsBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addNodeReports(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder builderForValue) {
        if (nodeReportsBuilder_ == null) {
          ensureNodeReportsIsMutable();
          nodeReports_.add(builderForValue.build());
          onChanged();
        } else {
          nodeReportsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addNodeReports(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder builderForValue) {
        if (nodeReportsBuilder_ == null) {
          ensureNodeReportsIsMutable();
          nodeReports_.add(index, builderForValue.build());
          onChanged();
        } else {
          nodeReportsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllNodeReports(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto> values) {
        if (nodeReportsBuilder_ == null) {
          ensureNodeReportsIsMutable();
          super.addAll(values, nodeReports_);
          onChanged();
        } else {
          nodeReportsBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearNodeReports() {
        if (nodeReportsBuilder_ == null) {
          nodeReports_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          nodeReportsBuilder_.clear();
        }
        return this;
      }
      public Builder removeNodeReports(int index) {
        if (nodeReportsBuilder_ == null) {
          ensureNodeReportsIsMutable();
          nodeReports_.remove(index);
          onChanged();
        } else {
          nodeReportsBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder getNodeReportsBuilder(
          int index) {
        return getNodeReportsFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder getNodeReportsOrBuilder(
          int index) {
        if (nodeReportsBuilder_ == null) {
          return nodeReports_.get(index);  } else {
          return nodeReportsBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> 
           getNodeReportsOrBuilderList() {
        if (nodeReportsBuilder_ != null) {
          return nodeReportsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(nodeReports_);
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder addNodeReportsBuilder() {
        return getNodeReportsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.getDefaultInstance());
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder addNodeReportsBuilder(
          int index) {
        return getNodeReportsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder> 
           getNodeReportsBuilderList() {
        return getNodeReportsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder> 
          getNodeReportsFieldBuilder() {
        if (nodeReportsBuilder_ == null) {
          nodeReportsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder>(
                  nodeReports_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          nodeReports_ = null;
        }
        return nodeReportsBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:GetClusterNodesResponseProto)
    }
    
    static {
      defaultInstance = new GetClusterNodesResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetClusterNodesResponseProto)
  }
  
  public interface GetQueueInfoRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional string queueName = 1;
    boolean hasQueueName();
    String getQueueName();
    
    // optional bool includeApplications = 2;
    boolean hasIncludeApplications();
    boolean getIncludeApplications();
    
    // optional bool includeChildQueues = 3;
    boolean hasIncludeChildQueues();
    boolean getIncludeChildQueues();
    
    // optional bool recursive = 4;
    boolean hasRecursive();
    boolean getRecursive();
  }
  public static final class GetQueueInfoRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements GetQueueInfoRequestProtoOrBuilder {
    // Use GetQueueInfoRequestProto.newBuilder() to construct.
    private GetQueueInfoRequestProto(Builder builder) {
      super(builder);
    }
    private GetQueueInfoRequestProto(boolean noInit) {}
    
    private static final GetQueueInfoRequestProto defaultInstance;
    public static GetQueueInfoRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetQueueInfoRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueInfoRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueInfoRequestProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional string queueName = 1;
    public static final int QUEUENAME_FIELD_NUMBER = 1;
    private java.lang.Object queueName_;
    public boolean hasQueueName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public String getQueueName() {
      java.lang.Object ref = queueName_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (com.google.protobuf.Internal.isValidUtf8(bs)) {
          queueName_ = s;
        }
        return s;
      }
    }
    private com.google.protobuf.ByteString getQueueNameBytes() {
      java.lang.Object ref = queueName_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8((String) ref);
        queueName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    
    // optional bool includeApplications = 2;
    public static final int INCLUDEAPPLICATIONS_FIELD_NUMBER = 2;
    private boolean includeApplications_;
    public boolean hasIncludeApplications() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public boolean getIncludeApplications() {
      return includeApplications_;
    }
    
    // optional bool includeChildQueues = 3;
    public static final int INCLUDECHILDQUEUES_FIELD_NUMBER = 3;
    private boolean includeChildQueues_;
    public boolean hasIncludeChildQueues() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public boolean getIncludeChildQueues() {
      return includeChildQueues_;
    }
    
    // optional bool recursive = 4;
    public static final int RECURSIVE_FIELD_NUMBER = 4;
    private boolean recursive_;
    public boolean hasRecursive() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public boolean getRecursive() {
      return recursive_;
    }
    
    private void initFields() {
      queueName_ = "";
      includeApplications_ = false;
      includeChildQueues_ = false;
      recursive_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getQueueNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, includeApplications_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(3, includeChildQueues_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBool(4, recursive_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getQueueNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, includeApplications_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, includeChildQueues_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, recursive_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto) obj;
      
      boolean result = true;
      result = result && (hasQueueName() == other.hasQueueName());
      if (hasQueueName()) {
        result = result && getQueueName()
            .equals(other.getQueueName());
      }
      result = result && (hasIncludeApplications() == other.hasIncludeApplications());
      if (hasIncludeApplications()) {
        result = result && (getIncludeApplications()
            == other.getIncludeApplications());
      }
      result = result && (hasIncludeChildQueues() == other.hasIncludeChildQueues());
      if (hasIncludeChildQueues()) {
        result = result && (getIncludeChildQueues()
            == other.getIncludeChildQueues());
      }
      result = result && (hasRecursive() == other.hasRecursive());
      if (hasRecursive()) {
        result = result && (getRecursive()
            == other.getRecursive());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasQueueName()) {
        hash = (37 * hash) + QUEUENAME_FIELD_NUMBER;
        hash = (53 * hash) + getQueueName().hashCode();
      }
      if (hasIncludeApplications()) {
        hash = (37 * hash) + INCLUDEAPPLICATIONS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getIncludeApplications());
      }
      if (hasIncludeChildQueues()) {
        hash = (37 * hash) + INCLUDECHILDQUEUES_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getIncludeChildQueues());
      }
      if (hasRecursive()) {
        hash = (37 * hash) + RECURSIVE_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getRecursive());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueInfoRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueInfoRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        queueName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        includeApplications_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        includeChildQueues_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        recursive_ = false;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.queueName_ = queueName_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.includeApplications_ = includeApplications_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.includeChildQueues_ = includeChildQueues_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.recursive_ = recursive_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto.getDefaultInstance()) return this;
        if (other.hasQueueName()) {
          setQueueName(other.getQueueName());
        }
        if (other.hasIncludeApplications()) {
          setIncludeApplications(other.getIncludeApplications());
        }
        if (other.hasIncludeChildQueues()) {
          setIncludeChildQueues(other.getIncludeChildQueues());
        }
        if (other.hasRecursive()) {
          setRecursive(other.getRecursive());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              queueName_ = input.readBytes();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              includeApplications_ = input.readBool();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              includeChildQueues_ = input.readBool();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              recursive_ = input.readBool();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional string queueName = 1;
      private java.lang.Object queueName_ = "";
      public boolean hasQueueName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public String getQueueName() {
        java.lang.Object ref = queueName_;
        if (!(ref instanceof String)) {
          String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
          queueName_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      public Builder setQueueName(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }
      public Builder clearQueueName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        queueName_ = getDefaultInstance().getQueueName();
        onChanged();
        return this;
      }
      void setQueueName(com.google.protobuf.ByteString value) {
        bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
      }
      
      // optional bool includeApplications = 2;
      private boolean includeApplications_ ;
      public boolean hasIncludeApplications() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public boolean getIncludeApplications() {
        return includeApplications_;
      }
      public Builder setIncludeApplications(boolean value) {
        bitField0_ |= 0x00000002;
        includeApplications_ = value;
        onChanged();
        return this;
      }
      public Builder clearIncludeApplications() {
        bitField0_ = (bitField0_ & ~0x00000002);
        includeApplications_ = false;
        onChanged();
        return this;
      }
      
      // optional bool includeChildQueues = 3;
      private boolean includeChildQueues_ ;
      public boolean hasIncludeChildQueues() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public boolean getIncludeChildQueues() {
        return includeChildQueues_;
      }
      public Builder setIncludeChildQueues(boolean value) {
        bitField0_ |= 0x00000004;
        includeChildQueues_ = value;
        onChanged();
        return this;
      }
      public Builder clearIncludeChildQueues() {
        bitField0_ = (bitField0_ & ~0x00000004);
        includeChildQueues_ = false;
        onChanged();
        return this;
      }
      
      // optional bool recursive = 4;
      private boolean recursive_ ;
      public boolean hasRecursive() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public boolean getRecursive() {
        return recursive_;
      }
      public Builder setRecursive(boolean value) {
        bitField0_ |= 0x00000008;
        recursive_ = value;
        onChanged();
        return this;
      }
      public Builder clearRecursive() {
        bitField0_ = (bitField0_ & ~0x00000008);
        recursive_ = false;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:GetQueueInfoRequestProto)
    }
    
    static {
      defaultInstance = new GetQueueInfoRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetQueueInfoRequestProto)
  }
  
  public interface GetQueueInfoResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .QueueInfoProto queueInfo = 1;
    boolean hasQueueInfo();
    org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getQueueInfo();
    org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getQueueInfoOrBuilder();
  }
  public static final class GetQueueInfoResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements GetQueueInfoResponseProtoOrBuilder {
    // Use GetQueueInfoResponseProto.newBuilder() to construct.
    private GetQueueInfoResponseProto(Builder builder) {
      super(builder);
    }
    private GetQueueInfoResponseProto(boolean noInit) {}
    
    private static final GetQueueInfoResponseProto defaultInstance;
    public static GetQueueInfoResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetQueueInfoResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueInfoResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueInfoResponseProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .QueueInfoProto queueInfo = 1;
    public static final int QUEUEINFO_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto queueInfo_;
    public boolean hasQueueInfo() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getQueueInfo() {
      return queueInfo_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getQueueInfoOrBuilder() {
      return queueInfo_;
    }
    
    private void initFields() {
      queueInfo_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, queueInfo_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, queueInfo_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto) obj;
      
      boolean result = true;
      result = result && (hasQueueInfo() == other.hasQueueInfo());
      if (hasQueueInfo()) {
        result = result && getQueueInfo()
            .equals(other.getQueueInfo());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasQueueInfo()) {
        hash = (37 * hash) + QUEUEINFO_FIELD_NUMBER;
        hash = (53 * hash) + getQueueInfo().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueInfoResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueInfoResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getQueueInfoFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (queueInfoBuilder_ == null) {
          queueInfo_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance();
        } else {
          queueInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (queueInfoBuilder_ == null) {
          result.queueInfo_ = queueInfo_;
        } else {
          result.queueInfo_ = queueInfoBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto.getDefaultInstance()) return this;
        if (other.hasQueueInfo()) {
          mergeQueueInfo(other.getQueueInfo());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.newBuilder();
              if (hasQueueInfo()) {
                subBuilder.mergeFrom(getQueueInfo());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setQueueInfo(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .QueueInfoProto queueInfo = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto queueInfo_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> queueInfoBuilder_;
      public boolean hasQueueInfo() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getQueueInfo() {
        if (queueInfoBuilder_ == null) {
          return queueInfo_;
        } else {
          return queueInfoBuilder_.getMessage();
        }
      }
      public Builder setQueueInfo(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto value) {
        if (queueInfoBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          queueInfo_ = value;
          onChanged();
        } else {
          queueInfoBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setQueueInfo(
          org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder builderForValue) {
        if (queueInfoBuilder_ == null) {
          queueInfo_ = builderForValue.build();
          onChanged();
        } else {
          queueInfoBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeQueueInfo(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto value) {
        if (queueInfoBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              queueInfo_ != org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance()) {
            queueInfo_ =
              org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.newBuilder(queueInfo_).mergeFrom(value).buildPartial();
          } else {
            queueInfo_ = value;
          }
          onChanged();
        } else {
          queueInfoBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearQueueInfo() {
        if (queueInfoBuilder_ == null) {
          queueInfo_ = org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance();
          onChanged();
        } else {
          queueInfoBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder getQueueInfoBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getQueueInfoFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getQueueInfoOrBuilder() {
        if (queueInfoBuilder_ != null) {
          return queueInfoBuilder_.getMessageOrBuilder();
        } else {
          return queueInfo_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
          getQueueInfoFieldBuilder() {
        if (queueInfoBuilder_ == null) {
          queueInfoBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder>(
                  queueInfo_,
                  getParentForChildren(),
                  isClean());
          queueInfo_ = null;
        }
        return queueInfoBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:GetQueueInfoResponseProto)
    }
    
    static {
      defaultInstance = new GetQueueInfoResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetQueueInfoResponseProto)
  }
  
  public interface GetQueueUserAclsInfoRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  public static final class GetQueueUserAclsInfoRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements GetQueueUserAclsInfoRequestProtoOrBuilder {
    // Use GetQueueUserAclsInfoRequestProto.newBuilder() to construct.
    private GetQueueUserAclsInfoRequestProto(Builder builder) {
      super(builder);
    }
    private GetQueueUserAclsInfoRequestProto(boolean noInit) {}
    
    private static final GetQueueUserAclsInfoRequestProto defaultInstance;
    public static GetQueueUserAclsInfoRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetQueueUserAclsInfoRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueUserAclsInfoRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueUserAclsInfoRequestProto_fieldAccessorTable;
    }
    
    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto) obj;
      
      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueUserAclsInfoRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueUserAclsInfoRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto(this);
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
          }
        }
      }
      
      
      // @@protoc_insertion_point(builder_scope:GetQueueUserAclsInfoRequestProto)
    }
    
    static {
      defaultInstance = new GetQueueUserAclsInfoRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetQueueUserAclsInfoRequestProto)
  }
  
  public interface GetQueueUserAclsInfoResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // repeated .QueueUserACLInfoProto queueUserAcls = 1;
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto> 
        getQueueUserAclsList();
    org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto getQueueUserAcls(int index);
    int getQueueUserAclsCount();
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder> 
        getQueueUserAclsOrBuilderList();
    org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder getQueueUserAclsOrBuilder(
        int index);
  }
  public static final class GetQueueUserAclsInfoResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements GetQueueUserAclsInfoResponseProtoOrBuilder {
    // Use GetQueueUserAclsInfoResponseProto.newBuilder() to construct.
    private GetQueueUserAclsInfoResponseProto(Builder builder) {
      super(builder);
    }
    private GetQueueUserAclsInfoResponseProto(boolean noInit) {}
    
    private static final GetQueueUserAclsInfoResponseProto defaultInstance;
    public static GetQueueUserAclsInfoResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetQueueUserAclsInfoResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueUserAclsInfoResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueUserAclsInfoResponseProto_fieldAccessorTable;
    }
    
    // repeated .QueueUserACLInfoProto queueUserAcls = 1;
    public static final int QUEUEUSERACLS_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto> queueUserAcls_;
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto> getQueueUserAclsList() {
      return queueUserAcls_;
    }
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder> 
        getQueueUserAclsOrBuilderList() {
      return queueUserAcls_;
    }
    public int getQueueUserAclsCount() {
      return queueUserAcls_.size();
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto getQueueUserAcls(int index) {
      return queueUserAcls_.get(index);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder getQueueUserAclsOrBuilder(
        int index) {
      return queueUserAcls_.get(index);
    }
    
    private void initFields() {
      queueUserAcls_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < queueUserAcls_.size(); i++) {
        output.writeMessage(1, queueUserAcls_.get(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      for (int i = 0; i < queueUserAcls_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, queueUserAcls_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto) obj;
      
      boolean result = true;
      result = result && getQueueUserAclsList()
          .equals(other.getQueueUserAclsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getQueueUserAclsCount() > 0) {
        hash = (37 * hash) + QUEUEUSERACLS_FIELD_NUMBER;
        hash = (53 * hash) + getQueueUserAclsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueUserAclsInfoResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetQueueUserAclsInfoResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getQueueUserAclsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (queueUserAclsBuilder_ == null) {
          queueUserAcls_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          queueUserAclsBuilder_.clear();
        }
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (queueUserAclsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            queueUserAcls_ = java.util.Collections.unmodifiableList(queueUserAcls_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.queueUserAcls_ = queueUserAcls_;
        } else {
          result.queueUserAcls_ = queueUserAclsBuilder_.build();
        }
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto.getDefaultInstance()) return this;
        if (queueUserAclsBuilder_ == null) {
          if (!other.queueUserAcls_.isEmpty()) {
            if (queueUserAcls_.isEmpty()) {
              queueUserAcls_ = other.queueUserAcls_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureQueueUserAclsIsMutable();
              queueUserAcls_.addAll(other.queueUserAcls_);
            }
            onChanged();
          }
        } else {
          if (!other.queueUserAcls_.isEmpty()) {
            if (queueUserAclsBuilder_.isEmpty()) {
              queueUserAclsBuilder_.dispose();
              queueUserAclsBuilder_ = null;
              queueUserAcls_ = other.queueUserAcls_;
              bitField0_ = (bitField0_ & ~0x00000001);
              queueUserAclsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getQueueUserAclsFieldBuilder() : null;
            } else {
              queueUserAclsBuilder_.addAllMessages(other.queueUserAcls_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addQueueUserAcls(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // repeated .QueueUserACLInfoProto queueUserAcls = 1;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto> queueUserAcls_ =
        java.util.Collections.emptyList();
      private void ensureQueueUserAclsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          queueUserAcls_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto>(queueUserAcls_);
          bitField0_ |= 0x00000001;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder> queueUserAclsBuilder_;
      
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto> getQueueUserAclsList() {
        if (queueUserAclsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(queueUserAcls_);
        } else {
          return queueUserAclsBuilder_.getMessageList();
        }
      }
      public int getQueueUserAclsCount() {
        if (queueUserAclsBuilder_ == null) {
          return queueUserAcls_.size();
        } else {
          return queueUserAclsBuilder_.getCount();
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto getQueueUserAcls(int index) {
        if (queueUserAclsBuilder_ == null) {
          return queueUserAcls_.get(index);
        } else {
          return queueUserAclsBuilder_.getMessage(index);
        }
      }
      public Builder setQueueUserAcls(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto value) {
        if (queueUserAclsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.set(index, value);
          onChanged();
        } else {
          queueUserAclsBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setQueueUserAcls(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder builderForValue) {
        if (queueUserAclsBuilder_ == null) {
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.set(index, builderForValue.build());
          onChanged();
        } else {
          queueUserAclsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addQueueUserAcls(org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto value) {
        if (queueUserAclsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.add(value);
          onChanged();
        } else {
          queueUserAclsBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addQueueUserAcls(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto value) {
        if (queueUserAclsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.add(index, value);
          onChanged();
        } else {
          queueUserAclsBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addQueueUserAcls(
          org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder builderForValue) {
        if (queueUserAclsBuilder_ == null) {
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.add(builderForValue.build());
          onChanged();
        } else {
          queueUserAclsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addQueueUserAcls(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder builderForValue) {
        if (queueUserAclsBuilder_ == null) {
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.add(index, builderForValue.build());
          onChanged();
        } else {
          queueUserAclsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllQueueUserAcls(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto> values) {
        if (queueUserAclsBuilder_ == null) {
          ensureQueueUserAclsIsMutable();
          super.addAll(values, queueUserAcls_);
          onChanged();
        } else {
          queueUserAclsBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearQueueUserAcls() {
        if (queueUserAclsBuilder_ == null) {
          queueUserAcls_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          queueUserAclsBuilder_.clear();
        }
        return this;
      }
      public Builder removeQueueUserAcls(int index) {
        if (queueUserAclsBuilder_ == null) {
          ensureQueueUserAclsIsMutable();
          queueUserAcls_.remove(index);
          onChanged();
        } else {
          queueUserAclsBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder getQueueUserAclsBuilder(
          int index) {
        return getQueueUserAclsFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder getQueueUserAclsOrBuilder(
          int index) {
        if (queueUserAclsBuilder_ == null) {
          return queueUserAcls_.get(index);  } else {
          return queueUserAclsBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder> 
           getQueueUserAclsOrBuilderList() {
        if (queueUserAclsBuilder_ != null) {
          return queueUserAclsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(queueUserAcls_);
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder addQueueUserAclsBuilder() {
        return getQueueUserAclsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.getDefaultInstance());
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder addQueueUserAclsBuilder(
          int index) {
        return getQueueUserAclsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder> 
           getQueueUserAclsBuilderList() {
        return getQueueUserAclsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder> 
          getQueueUserAclsFieldBuilder() {
        if (queueUserAclsBuilder_ == null) {
          queueUserAclsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder>(
                  queueUserAcls_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          queueUserAcls_ = null;
        }
        return queueUserAclsBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:GetQueueUserAclsInfoResponseProto)
    }
    
    static {
      defaultInstance = new GetQueueUserAclsInfoResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetQueueUserAclsInfoResponseProto)
  }
  
  public interface GetDelegationTokenRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional string renewer = 1;
    boolean hasRenewer();
    String getRenewer();
  }
  public static final class GetDelegationTokenRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements GetDelegationTokenRequestProtoOrBuilder {
    // Use GetDelegationTokenRequestProto.newBuilder() to construct.
    private GetDelegationTokenRequestProto(Builder builder) {
      super(builder);
    }
    private GetDelegationTokenRequestProto(boolean noInit) {}
    
    private static final GetDelegationTokenRequestProto defaultInstance;
    public static GetDelegationTokenRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetDelegationTokenRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetDelegationTokenRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetDelegationTokenRequestProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional string renewer = 1;
    public static final int RENEWER_FIELD_NUMBER = 1;
    private java.lang.Object renewer_;
    public boolean hasRenewer() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public String getRenewer() {
      java.lang.Object ref = renewer_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (com.google.protobuf.Internal.isValidUtf8(bs)) {
          renewer_ = s;
        }
        return s;
      }
    }
    private com.google.protobuf.ByteString getRenewerBytes() {
      java.lang.Object ref = renewer_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8((String) ref);
        renewer_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    
    private void initFields() {
      renewer_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getRenewerBytes());
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getRenewerBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto) obj;
      
      boolean result = true;
      result = result && (hasRenewer() == other.hasRenewer());
      if (hasRenewer()) {
        result = result && getRenewer()
            .equals(other.getRenewer());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRenewer()) {
        hash = (37 * hash) + RENEWER_FIELD_NUMBER;
        hash = (53 * hash) + getRenewer().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetDelegationTokenRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetDelegationTokenRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        renewer_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.renewer_ = renewer_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto.getDefaultInstance()) return this;
        if (other.hasRenewer()) {
          setRenewer(other.getRenewer());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              renewer_ = input.readBytes();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional string renewer = 1;
      private java.lang.Object renewer_ = "";
      public boolean hasRenewer() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public String getRenewer() {
        java.lang.Object ref = renewer_;
        if (!(ref instanceof String)) {
          String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
          renewer_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      public Builder setRenewer(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        renewer_ = value;
        onChanged();
        return this;
      }
      public Builder clearRenewer() {
        bitField0_ = (bitField0_ & ~0x00000001);
        renewer_ = getDefaultInstance().getRenewer();
        onChanged();
        return this;
      }
      void setRenewer(com.google.protobuf.ByteString value) {
        bitField0_ |= 0x00000001;
        renewer_ = value;
        onChanged();
      }
      
      // @@protoc_insertion_point(builder_scope:GetDelegationTokenRequestProto)
    }
    
    static {
      defaultInstance = new GetDelegationTokenRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetDelegationTokenRequestProto)
  }
  
  public interface GetDelegationTokenResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .DelegationTokenProto application_token = 1;
    boolean hasApplicationToken();
    org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto getApplicationToken();
    org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProtoOrBuilder getApplicationTokenOrBuilder();
  }
  public static final class GetDelegationTokenResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements GetDelegationTokenResponseProtoOrBuilder {
    // Use GetDelegationTokenResponseProto.newBuilder() to construct.
    private GetDelegationTokenResponseProto(Builder builder) {
      super(builder);
    }
    private GetDelegationTokenResponseProto(boolean noInit) {}
    
    private static final GetDelegationTokenResponseProto defaultInstance;
    public static GetDelegationTokenResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetDelegationTokenResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetDelegationTokenResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetDelegationTokenResponseProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .DelegationTokenProto application_token = 1;
    public static final int APPLICATION_TOKEN_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto applicationToken_;
    public boolean hasApplicationToken() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto getApplicationToken() {
      return applicationToken_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProtoOrBuilder getApplicationTokenOrBuilder() {
      return applicationToken_;
    }
    
    private void initFields() {
      applicationToken_ = org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, applicationToken_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, applicationToken_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto) obj;
      
      boolean result = true;
      result = result && (hasApplicationToken() == other.hasApplicationToken());
      if (hasApplicationToken()) {
        result = result && getApplicationToken()
            .equals(other.getApplicationToken());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasApplicationToken()) {
        hash = (37 * hash) + APPLICATION_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationToken().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetDelegationTokenResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetDelegationTokenResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getApplicationTokenFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (applicationTokenBuilder_ == null) {
          applicationToken_ = org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto.getDefaultInstance();
        } else {
          applicationTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationTokenBuilder_ == null) {
          result.applicationToken_ = applicationToken_;
        } else {
          result.applicationToken_ = applicationTokenBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto.getDefaultInstance()) return this;
        if (other.hasApplicationToken()) {
          mergeApplicationToken(other.getApplicationToken());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto.newBuilder();
              if (hasApplicationToken()) {
                subBuilder.mergeFrom(getApplicationToken());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setApplicationToken(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .DelegationTokenProto application_token = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto applicationToken_ = org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto, org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProtoOrBuilder> applicationTokenBuilder_;
      public boolean hasApplicationToken() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto getApplicationToken() {
        if (applicationTokenBuilder_ == null) {
          return applicationToken_;
        } else {
          return applicationTokenBuilder_.getMessage();
        }
      }
      public Builder setApplicationToken(org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto value) {
        if (applicationTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationToken_ = value;
          onChanged();
        } else {
          applicationTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setApplicationToken(
          org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto.Builder builderForValue) {
        if (applicationTokenBuilder_ == null) {
          applicationToken_ = builderForValue.build();
          onChanged();
        } else {
          applicationTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeApplicationToken(org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto value) {
        if (applicationTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationToken_ != org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto.getDefaultInstance()) {
            applicationToken_ =
              org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto.newBuilder(applicationToken_).mergeFrom(value).buildPartial();
          } else {
            applicationToken_ = value;
          }
          onChanged();
        } else {
          applicationTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearApplicationToken() {
        if (applicationTokenBuilder_ == null) {
          applicationToken_ = org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto.getDefaultInstance();
          onChanged();
        } else {
          applicationTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto.Builder getApplicationTokenBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationTokenFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProtoOrBuilder getApplicationTokenOrBuilder() {
        if (applicationTokenBuilder_ != null) {
          return applicationTokenBuilder_.getMessageOrBuilder();
        } else {
          return applicationToken_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto, org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProtoOrBuilder> 
          getApplicationTokenFieldBuilder() {
        if (applicationTokenBuilder_ == null) {
          applicationTokenBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto, org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.DelegationTokenProtoOrBuilder>(
                  applicationToken_,
                  getParentForChildren(),
                  isClean());
          applicationToken_ = null;
        }
        return applicationTokenBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:GetDelegationTokenResponseProto)
    }
    
    static {
      defaultInstance = new GetDelegationTokenResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetDelegationTokenResponseProto)
  }
  
  public interface StartContainerRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .ContainerLaunchContextProto container_launch_context = 1;
    boolean hasContainerLaunchContext();
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getContainerLaunchContext();
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getContainerLaunchContextOrBuilder();
  }
  public static final class StartContainerRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements StartContainerRequestProtoOrBuilder {
    // Use StartContainerRequestProto.newBuilder() to construct.
    private StartContainerRequestProto(Builder builder) {
      super(builder);
    }
    private StartContainerRequestProto(boolean noInit) {}
    
    private static final StartContainerRequestProto defaultInstance;
    public static StartContainerRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public StartContainerRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StartContainerRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StartContainerRequestProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .ContainerLaunchContextProto container_launch_context = 1;
    public static final int CONTAINER_LAUNCH_CONTEXT_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto containerLaunchContext_;
    public boolean hasContainerLaunchContext() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getContainerLaunchContext() {
      return containerLaunchContext_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getContainerLaunchContextOrBuilder() {
      return containerLaunchContext_;
    }
    
    private void initFields() {
      containerLaunchContext_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerLaunchContext_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerLaunchContext_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto) obj;
      
      boolean result = true;
      result = result && (hasContainerLaunchContext() == other.hasContainerLaunchContext());
      if (hasContainerLaunchContext()) {
        result = result && getContainerLaunchContext()
            .equals(other.getContainerLaunchContext());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerLaunchContext()) {
        hash = (37 * hash) + CONTAINER_LAUNCH_CONTEXT_FIELD_NUMBER;
        hash = (53 * hash) + getContainerLaunchContext().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StartContainerRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StartContainerRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerLaunchContextFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (containerLaunchContextBuilder_ == null) {
          containerLaunchContext_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
        } else {
          containerLaunchContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerLaunchContextBuilder_ == null) {
          result.containerLaunchContext_ = containerLaunchContext_;
        } else {
          result.containerLaunchContext_ = containerLaunchContextBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.getDefaultInstance()) return this;
        if (other.hasContainerLaunchContext()) {
          mergeContainerLaunchContext(other.getContainerLaunchContext());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.newBuilder();
              if (hasContainerLaunchContext()) {
                subBuilder.mergeFrom(getContainerLaunchContext());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setContainerLaunchContext(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .ContainerLaunchContextProto container_launch_context = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto containerLaunchContext_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder> containerLaunchContextBuilder_;
      public boolean hasContainerLaunchContext() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getContainerLaunchContext() {
        if (containerLaunchContextBuilder_ == null) {
          return containerLaunchContext_;
        } else {
          return containerLaunchContextBuilder_.getMessage();
        }
      }
      public Builder setContainerLaunchContext(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto value) {
        if (containerLaunchContextBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerLaunchContext_ = value;
          onChanged();
        } else {
          containerLaunchContextBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setContainerLaunchContext(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder builderForValue) {
        if (containerLaunchContextBuilder_ == null) {
          containerLaunchContext_ = builderForValue.build();
          onChanged();
        } else {
          containerLaunchContextBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeContainerLaunchContext(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto value) {
        if (containerLaunchContextBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerLaunchContext_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance()) {
            containerLaunchContext_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.newBuilder(containerLaunchContext_).mergeFrom(value).buildPartial();
          } else {
            containerLaunchContext_ = value;
          }
          onChanged();
        } else {
          containerLaunchContextBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearContainerLaunchContext() {
        if (containerLaunchContextBuilder_ == null) {
          containerLaunchContext_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
          onChanged();
        } else {
          containerLaunchContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder getContainerLaunchContextBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerLaunchContextFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getContainerLaunchContextOrBuilder() {
        if (containerLaunchContextBuilder_ != null) {
          return containerLaunchContextBuilder_.getMessageOrBuilder();
        } else {
          return containerLaunchContext_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder> 
          getContainerLaunchContextFieldBuilder() {
        if (containerLaunchContextBuilder_ == null) {
          containerLaunchContextBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder>(
                  containerLaunchContext_,
                  getParentForChildren(),
                  isClean());
          containerLaunchContext_ = null;
        }
        return containerLaunchContextBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:StartContainerRequestProto)
    }
    
    static {
      defaultInstance = new StartContainerRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:StartContainerRequestProto)
  }
  
  public interface StartContainerResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // repeated .StringBytesMapProto service_response = 1;
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> 
        getServiceResponseList();
    org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServiceResponse(int index);
    int getServiceResponseCount();
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
        getServiceResponseOrBuilderList();
    org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServiceResponseOrBuilder(
        int index);
  }
  public static final class StartContainerResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements StartContainerResponseProtoOrBuilder {
    // Use StartContainerResponseProto.newBuilder() to construct.
    private StartContainerResponseProto(Builder builder) {
      super(builder);
    }
    private StartContainerResponseProto(boolean noInit) {}
    
    private static final StartContainerResponseProto defaultInstance;
    public static StartContainerResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public StartContainerResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StartContainerResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StartContainerResponseProto_fieldAccessorTable;
    }
    
    // repeated .StringBytesMapProto service_response = 1;
    public static final int SERVICE_RESPONSE_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> serviceResponse_;
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> getServiceResponseList() {
      return serviceResponse_;
    }
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
        getServiceResponseOrBuilderList() {
      return serviceResponse_;
    }
    public int getServiceResponseCount() {
      return serviceResponse_.size();
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServiceResponse(int index) {
      return serviceResponse_.get(index);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServiceResponseOrBuilder(
        int index) {
      return serviceResponse_.get(index);
    }
    
    private void initFields() {
      serviceResponse_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < serviceResponse_.size(); i++) {
        output.writeMessage(1, serviceResponse_.get(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      for (int i = 0; i < serviceResponse_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, serviceResponse_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto) obj;
      
      boolean result = true;
      result = result && getServiceResponseList()
          .equals(other.getServiceResponseList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getServiceResponseCount() > 0) {
        hash = (37 * hash) + SERVICE_RESPONSE_FIELD_NUMBER;
        hash = (53 * hash) + getServiceResponseList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StartContainerResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StartContainerResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getServiceResponseFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (serviceResponseBuilder_ == null) {
          serviceResponse_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          serviceResponseBuilder_.clear();
        }
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto(this);
        int from_bitField0_ = bitField0_;
        if (serviceResponseBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            serviceResponse_ = java.util.Collections.unmodifiableList(serviceResponse_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.serviceResponse_ = serviceResponse_;
        } else {
          result.serviceResponse_ = serviceResponseBuilder_.build();
        }
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto.getDefaultInstance()) return this;
        if (serviceResponseBuilder_ == null) {
          if (!other.serviceResponse_.isEmpty()) {
            if (serviceResponse_.isEmpty()) {
              serviceResponse_ = other.serviceResponse_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureServiceResponseIsMutable();
              serviceResponse_.addAll(other.serviceResponse_);
            }
            onChanged();
          }
        } else {
          if (!other.serviceResponse_.isEmpty()) {
            if (serviceResponseBuilder_.isEmpty()) {
              serviceResponseBuilder_.dispose();
              serviceResponseBuilder_ = null;
              serviceResponse_ = other.serviceResponse_;
              bitField0_ = (bitField0_ & ~0x00000001);
              serviceResponseBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getServiceResponseFieldBuilder() : null;
            } else {
              serviceResponseBuilder_.addAllMessages(other.serviceResponse_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addServiceResponse(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // repeated .StringBytesMapProto service_response = 1;
      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> serviceResponse_ =
        java.util.Collections.emptyList();
      private void ensureServiceResponseIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          serviceResponse_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto>(serviceResponse_);
          bitField0_ |= 0x00000001;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> serviceResponseBuilder_;
      
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> getServiceResponseList() {
        if (serviceResponseBuilder_ == null) {
          return java.util.Collections.unmodifiableList(serviceResponse_);
        } else {
          return serviceResponseBuilder_.getMessageList();
        }
      }
      public int getServiceResponseCount() {
        if (serviceResponseBuilder_ == null) {
          return serviceResponse_.size();
        } else {
          return serviceResponseBuilder_.getCount();
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServiceResponse(int index) {
        if (serviceResponseBuilder_ == null) {
          return serviceResponse_.get(index);
        } else {
          return serviceResponseBuilder_.getMessage(index);
        }
      }
      public Builder setServiceResponse(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (serviceResponseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServiceResponseIsMutable();
          serviceResponse_.set(index, value);
          onChanged();
        } else {
          serviceResponseBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setServiceResponse(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (serviceResponseBuilder_ == null) {
          ensureServiceResponseIsMutable();
          serviceResponse_.set(index, builderForValue.build());
          onChanged();
        } else {
          serviceResponseBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addServiceResponse(org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (serviceResponseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServiceResponseIsMutable();
          serviceResponse_.add(value);
          onChanged();
        } else {
          serviceResponseBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addServiceResponse(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (serviceResponseBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServiceResponseIsMutable();
          serviceResponse_.add(index, value);
          onChanged();
        } else {
          serviceResponseBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addServiceResponse(
          org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (serviceResponseBuilder_ == null) {
          ensureServiceResponseIsMutable();
          serviceResponse_.add(builderForValue.build());
          onChanged();
        } else {
          serviceResponseBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addServiceResponse(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (serviceResponseBuilder_ == null) {
          ensureServiceResponseIsMutable();
          serviceResponse_.add(index, builderForValue.build());
          onChanged();
        } else {
          serviceResponseBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllServiceResponse(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> values) {
        if (serviceResponseBuilder_ == null) {
          ensureServiceResponseIsMutable();
          super.addAll(values, serviceResponse_);
          onChanged();
        } else {
          serviceResponseBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearServiceResponse() {
        if (serviceResponseBuilder_ == null) {
          serviceResponse_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          serviceResponseBuilder_.clear();
        }
        return this;
      }
      public Builder removeServiceResponse(int index) {
        if (serviceResponseBuilder_ == null) {
          ensureServiceResponseIsMutable();
          serviceResponse_.remove(index);
          onChanged();
        } else {
          serviceResponseBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder getServiceResponseBuilder(
          int index) {
        return getServiceResponseFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServiceResponseOrBuilder(
          int index) {
        if (serviceResponseBuilder_ == null) {
          return serviceResponse_.get(index);  } else {
          return serviceResponseBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
           getServiceResponseOrBuilderList() {
        if (serviceResponseBuilder_ != null) {
          return serviceResponseBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(serviceResponse_);
        }
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder addServiceResponseBuilder() {
        return getServiceResponseFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance());
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder addServiceResponseBuilder(
          int index) {
        return getServiceResponseFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder> 
           getServiceResponseBuilderList() {
        return getServiceResponseFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
          getServiceResponseFieldBuilder() {
        if (serviceResponseBuilder_ == null) {
          serviceResponseBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder>(
                  serviceResponse_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          serviceResponse_ = null;
        }
        return serviceResponseBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:StartContainerResponseProto)
    }
    
    static {
      defaultInstance = new StartContainerResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:StartContainerResponseProto)
  }
  
  public interface StopContainerRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .ContainerIdProto container_id = 1;
    boolean hasContainerId();
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();
  }
  public static final class StopContainerRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements StopContainerRequestProtoOrBuilder {
    // Use StopContainerRequestProto.newBuilder() to construct.
    private StopContainerRequestProto(Builder builder) {
      super(builder);
    }
    private StopContainerRequestProto(boolean noInit) {}
    
    private static final StopContainerRequestProto defaultInstance;
    public static StopContainerRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public StopContainerRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StopContainerRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StopContainerRequestProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .ContainerIdProto container_id = 1;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_;
    }
    
    private void initFields() {
      containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerId_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto) obj;
      
      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StopContainerRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StopContainerRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder();
              if (hasContainerId()) {
                subBuilder.mergeFrom(getContainerId());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setContainerId(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .ContainerIdProto container_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:StopContainerRequestProto)
    }
    
    static {
      defaultInstance = new StopContainerRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:StopContainerRequestProto)
  }
  
  public interface StopContainerResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  public static final class StopContainerResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements StopContainerResponseProtoOrBuilder {
    // Use StopContainerResponseProto.newBuilder() to construct.
    private StopContainerResponseProto(Builder builder) {
      super(builder);
    }
    private StopContainerResponseProto(boolean noInit) {}
    
    private static final StopContainerResponseProto defaultInstance;
    public static StopContainerResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public StopContainerResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StopContainerResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StopContainerResponseProto_fieldAccessorTable;
    }
    
    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto) obj;
      
      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StopContainerResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_StopContainerResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto(this);
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
          }
        }
      }
      
      
      // @@protoc_insertion_point(builder_scope:StopContainerResponseProto)
    }
    
    static {
      defaultInstance = new StopContainerResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:StopContainerResponseProto)
  }
  
  public interface GetContainerStatusRequestProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .ContainerIdProto container_id = 1;
    boolean hasContainerId();
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();
  }
  public static final class GetContainerStatusRequestProto extends
      com.google.protobuf.GeneratedMessage
      implements GetContainerStatusRequestProtoOrBuilder {
    // Use GetContainerStatusRequestProto.newBuilder() to construct.
    private GetContainerStatusRequestProto(Builder builder) {
      super(builder);
    }
    private GetContainerStatusRequestProto(boolean noInit) {}
    
    private static final GetContainerStatusRequestProto defaultInstance;
    public static GetContainerStatusRequestProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetContainerStatusRequestProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetContainerStatusRequestProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetContainerStatusRequestProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .ContainerIdProto container_id = 1;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_;
    }
    
    private void initFields() {
      containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, containerId_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, containerId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto) obj;
      
      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetContainerStatusRequestProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetContainerStatusRequestProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder();
              if (hasContainerId()) {
                subBuilder.mergeFrom(getContainerId());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setContainerId(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .ContainerIdProto container_id = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  containerId_,
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:GetContainerStatusRequestProto)
    }
    
    static {
      defaultInstance = new GetContainerStatusRequestProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetContainerStatusRequestProto)
  }
  
  public interface GetContainerStatusResponseProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .ContainerStatusProto status = 1;
    boolean hasStatus();
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getStatus();
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder getStatusOrBuilder();
  }
  public static final class GetContainerStatusResponseProto extends
      com.google.protobuf.GeneratedMessage
      implements GetContainerStatusResponseProtoOrBuilder {
    // Use GetContainerStatusResponseProto.newBuilder() to construct.
    private GetContainerStatusResponseProto(Builder builder) {
      super(builder);
    }
    private GetContainerStatusResponseProto(boolean noInit) {}
    
    private static final GetContainerStatusResponseProto defaultInstance;
    public static GetContainerStatusResponseProto getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetContainerStatusResponseProto getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetContainerStatusResponseProto_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetContainerStatusResponseProto_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .ContainerStatusProto status = 1;
    public static final int STATUS_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto status_;
    public boolean hasStatus() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getStatus() {
      return status_;
    }
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder getStatusOrBuilder() {
      return status_;
    }
    
    private void initFields() {
      status_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, status_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, status_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto other = (org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto) obj;
      
      boolean result = true;
      result = result && (hasStatus() == other.hasStatus());
      if (hasStatus()) {
        result = result && getStatus()
            .equals(other.getStatus());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasStatus()) {
        hash = (37 * hash) + STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getStatus().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetContainerStatusResponseProto_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.internal_static_GetContainerStatusResponseProto_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getStatusFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (statusBuilder_ == null) {
          status_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance();
        } else {
          statusBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto.getDescriptor();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto.getDefaultInstance();
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto build() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto result = new org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (statusBuilder_ == null) {
          result.status_ = status_;
        } else {
          result.status_ = statusBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto.getDefaultInstance()) return this;
        if (other.hasStatus()) {
          mergeStatus(other.getStatus());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder subBuilder = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.newBuilder();
              if (hasStatus()) {
                subBuilder.mergeFrom(getStatus());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setStatus(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .ContainerStatusProto status = 1;
      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto status_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> statusBuilder_;
      public boolean hasStatus() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getStatus() {
        if (statusBuilder_ == null) {
          return status_;
        } else {
          return statusBuilder_.getMessage();
        }
      }
      public Builder setStatus(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto value) {
        if (statusBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          status_ = value;
          onChanged();
        } else {
          statusBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setStatus(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder builderForValue) {
        if (statusBuilder_ == null) {
          status_ = builderForValue.build();
          onChanged();
        } else {
          statusBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeStatus(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto value) {
        if (statusBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              status_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance()) {
            status_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.newBuilder(status_).mergeFrom(value).buildPartial();
          } else {
            status_ = value;
          }
          onChanged();
        } else {
          statusBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearStatus() {
        if (statusBuilder_ == null) {
          status_ = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance();
          onChanged();
        } else {
          statusBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder getStatusBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getStatusFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder getStatusOrBuilder() {
        if (statusBuilder_ != null) {
          return statusBuilder_.getMessageOrBuilder();
        } else {
          return status_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder> 
          getStatusFieldBuilder() {
        if (statusBuilder_ == null) {
          statusBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder>(
                  status_,
                  getParentForChildren(),
                  isClean());
          status_ = null;
        }
        return statusBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:GetContainerStatusResponseProto)
    }
    
    static {
      defaultInstance = new GetContainerStatusResponseProto(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetContainerStatusResponseProto)
  }
  
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_RegisterApplicationMasterRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_RegisterApplicationMasterRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_RegisterApplicationMasterResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_RegisterApplicationMasterResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_FinishApplicationMasterRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_FinishApplicationMasterRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_FinishApplicationMasterResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_FinishApplicationMasterResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_AllocateRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_AllocateRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_AllocateResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_AllocateResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetNewApplicationRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetNewApplicationRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetNewApplicationResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetNewApplicationResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetApplicationReportRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetApplicationReportRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetApplicationReportResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetApplicationReportResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_SubmitApplicationRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_SubmitApplicationRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_SubmitApplicationResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_SubmitApplicationResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_KillApplicationRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_KillApplicationRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_KillApplicationResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_KillApplicationResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetClusterMetricsRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetClusterMetricsRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetClusterMetricsResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetClusterMetricsResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetAllApplicationsRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetAllApplicationsRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetAllApplicationsResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetAllApplicationsResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetClusterNodesRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetClusterNodesRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetClusterNodesResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetClusterNodesResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetQueueInfoRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetQueueInfoRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetQueueInfoResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetQueueInfoResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetQueueUserAclsInfoRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetQueueUserAclsInfoRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetQueueUserAclsInfoResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetQueueUserAclsInfoResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetDelegationTokenRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetDelegationTokenRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetDelegationTokenResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetDelegationTokenResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_StartContainerRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_StartContainerRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_StartContainerResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_StartContainerResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_StopContainerRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_StopContainerRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_StopContainerResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_StopContainerResponseProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetContainerStatusRequestProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetContainerStatusRequestProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetContainerStatusResponseProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetContainerStatusResponseProto_fieldAccessorTable;
  
  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\031yarn_service_protos.proto\032\021yarn_protos" +
      ".proto\"\231\001\n%RegisterApplicationMasterRequ" +
      "estProto\022:\n\026application_attempt_id\030\001 \001(\013" +
      "2\032.ApplicationAttemptIdProto\022\014\n\004host\030\002 \001" +
      "(\t\022\020\n\010rpc_port\030\003 \001(\005\022\024\n\014tracking_url\030\004 \001" +
      "(\t\"\261\001\n&RegisterApplicationMasterResponse" +
      "Proto\022)\n\021minimumCapability\030\001 \001(\0132\016.Resou" +
      "rceProto\022)\n\021maximumCapability\030\002 \001(\0132\016.Re" +
      "sourceProto\0221\n\020application_ACLs\030\003 \003(\0132\027." +
      "ApplicationACLMapProto\"\314\001\n#FinishApplica",
      "tionMasterRequestProto\022:\n\026application_at" +
      "tempt_id\030\001 \001(\0132\032.ApplicationAttemptIdPro" +
      "to\022\023\n\013diagnostics\030\002 \001(\t\022\024\n\014tracking_url\030" +
      "\003 \001(\t\022>\n\030final_application_status\030\004 \001(\0162" +
      "\034.FinalApplicationStatusProto\"&\n$FinishA" +
      "pplicationMasterResponseProto\"\301\001\n\024Alloca" +
      "teRequestProto\022:\n\026application_attempt_id" +
      "\030\001 \001(\0132\032.ApplicationAttemptIdProto\022\"\n\003as" +
      "k\030\002 \003(\0132\025.ResourceRequestProto\022\"\n\007releas" +
      "e\030\003 \003(\0132\021.ContainerIdProto\022\023\n\013response_i",
      "d\030\004 \001(\005\022\020\n\010progress\030\005 \001(\002\"Y\n\025AllocateRes" +
      "ponseProto\022%\n\013AM_response\030\001 \001(\0132\020.AMResp" +
      "onseProto\022\031\n\021num_cluster_nodes\030\002 \001(\005\"\037\n\035" +
      "GetNewApplicationRequestProto\"\243\001\n\036GetNew" +
      "ApplicationResponseProto\022+\n\016application_" +
      "id\030\001 \001(\0132\023.ApplicationIdProto\022)\n\021minimum" +
      "Capability\030\002 \001(\0132\016.ResourceProto\022)\n\021maxi" +
      "mumCapability\030\003 \001(\0132\016.ResourceProto\"O\n G" +
      "etApplicationReportRequestProto\022+\n\016appli" +
      "cation_id\030\001 \001(\0132\023.ApplicationIdProto\"X\n!",
      "GetApplicationReportResponseProto\0223\n\022app" +
      "lication_report\030\001 \001(\0132\027.ApplicationRepor" +
      "tProto\"k\n\035SubmitApplicationRequestProto\022" +
      "J\n\036application_submission_context\030\001 \001(\0132" +
      "\".ApplicationSubmissionContextProto\" \n\036S" +
      "ubmitApplicationResponseProto\"J\n\033KillApp" +
      "licationRequestProto\022+\n\016application_id\030\001" +
      " \001(\0132\023.ApplicationIdProto\"\036\n\034KillApplica" +
      "tionResponseProto\"\037\n\035GetClusterMetricsRe" +
      "questProto\"S\n\036GetClusterMetricsResponseP",
      "roto\0221\n\017cluster_metrics\030\001 \001(\0132\030.YarnClus" +
      "terMetricsProto\" \n\036GetAllApplicationsReq" +
      "uestProto\"P\n\037GetAllApplicationsResponseP" +
      "roto\022-\n\014applications\030\001 \003(\0132\027.Application" +
      "ReportProto\"\035\n\033GetClusterNodesRequestPro" +
      "to\"E\n\034GetClusterNodesResponseProto\022%\n\013no" +
      "deReports\030\001 \003(\0132\020.NodeReportProto\"y\n\030Get" +
      "QueueInfoRequestProto\022\021\n\tqueueName\030\001 \001(\t" +
      "\022\033\n\023includeApplications\030\002 \001(\010\022\032\n\022include" +
      "ChildQueues\030\003 \001(\010\022\021\n\trecursive\030\004 \001(\010\"?\n\031",
      "GetQueueInfoResponseProto\022\"\n\tqueueInfo\030\001" +
      " \001(\0132\017.QueueInfoProto\"\"\n GetQueueUserAcl" +
      "sInfoRequestProto\"R\n!GetQueueUserAclsInf" +
      "oResponseProto\022-\n\rqueueUserAcls\030\001 \003(\0132\026." +
      "QueueUserACLInfoProto\"1\n\036GetDelegationTo" +
      "kenRequestProto\022\017\n\007renewer\030\001 \001(\t\"S\n\037GetD" +
      "elegationTokenResponseProto\0220\n\021applicati" +
      "on_token\030\001 \001(\0132\025.DelegationTokenProto\"\\\n" +
      "\032StartContainerRequestProto\022>\n\030container" +
      "_launch_context\030\001 \001(\0132\034.ContainerLaunchC",
      "ontextProto\"M\n\033StartContainerResponsePro" +
      "to\022.\n\020service_response\030\001 \003(\0132\024.StringByt" +
      "esMapProto\"D\n\031StopContainerRequestProto\022" +
      "\'\n\014container_id\030\001 \001(\0132\021.ContainerIdProto" +
      "\"\034\n\032StopContainerResponseProto\"I\n\036GetCon" +
      "tainerStatusRequestProto\022\'\n\014container_id" +
      "\030\001 \001(\0132\021.ContainerIdProto\"H\n\037GetContaine" +
      "rStatusResponseProto\022%\n\006status\030\001 \001(\0132\025.C" +
      "ontainerStatusProtoB7\n\034org.apache.hadoop" +
      ".yarn.protoB\021YarnServiceProtos\210\001\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_RegisterApplicationMasterRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_RegisterApplicationMasterRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_RegisterApplicationMasterRequestProto_descriptor,
              new java.lang.String[] { "ApplicationAttemptId", "Host", "RpcPort", "TrackingUrl", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterRequestProto.Builder.class);
          internal_static_RegisterApplicationMasterResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_RegisterApplicationMasterResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_RegisterApplicationMasterResponseProto_descriptor,
              new java.lang.String[] { "MinimumCapability", "MaximumCapability", "ApplicationACLs", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.RegisterApplicationMasterResponseProto.Builder.class);
          internal_static_FinishApplicationMasterRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(2);
          internal_static_FinishApplicationMasterRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_FinishApplicationMasterRequestProto_descriptor,
              new java.lang.String[] { "ApplicationAttemptId", "Diagnostics", "TrackingUrl", "FinalApplicationStatus", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterRequestProto.Builder.class);
          internal_static_FinishApplicationMasterResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(3);
          internal_static_FinishApplicationMasterResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_FinishApplicationMasterResponseProto_descriptor,
              new java.lang.String[] { },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.FinishApplicationMasterResponseProto.Builder.class);
          internal_static_AllocateRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(4);
          internal_static_AllocateRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_AllocateRequestProto_descriptor,
              new java.lang.String[] { "ApplicationAttemptId", "Ask", "Release", "ResponseId", "Progress", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateRequestProto.Builder.class);
          internal_static_AllocateResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(5);
          internal_static_AllocateResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_AllocateResponseProto_descriptor,
              new java.lang.String[] { "AMResponse", "NumClusterNodes", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.AllocateResponseProto.Builder.class);
          internal_static_GetNewApplicationRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(6);
          internal_static_GetNewApplicationRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetNewApplicationRequestProto_descriptor,
              new java.lang.String[] { },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationRequestProto.Builder.class);
          internal_static_GetNewApplicationResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(7);
          internal_static_GetNewApplicationResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetNewApplicationResponseProto_descriptor,
              new java.lang.String[] { "ApplicationId", "MinimumCapability", "MaximumCapability", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetNewApplicationResponseProto.Builder.class);
          internal_static_GetApplicationReportRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(8);
          internal_static_GetApplicationReportRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetApplicationReportRequestProto_descriptor,
              new java.lang.String[] { "ApplicationId", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportRequestProto.Builder.class);
          internal_static_GetApplicationReportResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(9);
          internal_static_GetApplicationReportResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetApplicationReportResponseProto_descriptor,
              new java.lang.String[] { "ApplicationReport", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetApplicationReportResponseProto.Builder.class);
          internal_static_SubmitApplicationRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(10);
          internal_static_SubmitApplicationRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_SubmitApplicationRequestProto_descriptor,
              new java.lang.String[] { "ApplicationSubmissionContext", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationRequestProto.Builder.class);
          internal_static_SubmitApplicationResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(11);
          internal_static_SubmitApplicationResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_SubmitApplicationResponseProto_descriptor,
              new java.lang.String[] { },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.SubmitApplicationResponseProto.Builder.class);
          internal_static_KillApplicationRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(12);
          internal_static_KillApplicationRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_KillApplicationRequestProto_descriptor,
              new java.lang.String[] { "ApplicationId", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationRequestProto.Builder.class);
          internal_static_KillApplicationResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(13);
          internal_static_KillApplicationResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_KillApplicationResponseProto_descriptor,
              new java.lang.String[] { },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.KillApplicationResponseProto.Builder.class);
          internal_static_GetClusterMetricsRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(14);
          internal_static_GetClusterMetricsRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetClusterMetricsRequestProto_descriptor,
              new java.lang.String[] { },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsRequestProto.Builder.class);
          internal_static_GetClusterMetricsResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(15);
          internal_static_GetClusterMetricsResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetClusterMetricsResponseProto_descriptor,
              new java.lang.String[] { "ClusterMetrics", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterMetricsResponseProto.Builder.class);
          internal_static_GetAllApplicationsRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(16);
          internal_static_GetAllApplicationsRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetAllApplicationsRequestProto_descriptor,
              new java.lang.String[] { },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsRequestProto.Builder.class);
          internal_static_GetAllApplicationsResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(17);
          internal_static_GetAllApplicationsResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetAllApplicationsResponseProto_descriptor,
              new java.lang.String[] { "Applications", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetAllApplicationsResponseProto.Builder.class);
          internal_static_GetClusterNodesRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(18);
          internal_static_GetClusterNodesRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetClusterNodesRequestProto_descriptor,
              new java.lang.String[] { },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesRequestProto.Builder.class);
          internal_static_GetClusterNodesResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(19);
          internal_static_GetClusterNodesResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetClusterNodesResponseProto_descriptor,
              new java.lang.String[] { "NodeReports", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetClusterNodesResponseProto.Builder.class);
          internal_static_GetQueueInfoRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(20);
          internal_static_GetQueueInfoRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetQueueInfoRequestProto_descriptor,
              new java.lang.String[] { "QueueName", "IncludeApplications", "IncludeChildQueues", "Recursive", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoRequestProto.Builder.class);
          internal_static_GetQueueInfoResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(21);
          internal_static_GetQueueInfoResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetQueueInfoResponseProto_descriptor,
              new java.lang.String[] { "QueueInfo", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueInfoResponseProto.Builder.class);
          internal_static_GetQueueUserAclsInfoRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(22);
          internal_static_GetQueueUserAclsInfoRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetQueueUserAclsInfoRequestProto_descriptor,
              new java.lang.String[] { },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoRequestProto.Builder.class);
          internal_static_GetQueueUserAclsInfoResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(23);
          internal_static_GetQueueUserAclsInfoResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetQueueUserAclsInfoResponseProto_descriptor,
              new java.lang.String[] { "QueueUserAcls", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetQueueUserAclsInfoResponseProto.Builder.class);
          internal_static_GetDelegationTokenRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(24);
          internal_static_GetDelegationTokenRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetDelegationTokenRequestProto_descriptor,
              new java.lang.String[] { "Renewer", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenRequestProto.Builder.class);
          internal_static_GetDelegationTokenResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(25);
          internal_static_GetDelegationTokenResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetDelegationTokenResponseProto_descriptor,
              new java.lang.String[] { "ApplicationToken", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetDelegationTokenResponseProto.Builder.class);
          internal_static_StartContainerRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(26);
          internal_static_StartContainerRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_StartContainerRequestProto_descriptor,
              new java.lang.String[] { "ContainerLaunchContext", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerRequestProto.Builder.class);
          internal_static_StartContainerResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(27);
          internal_static_StartContainerResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_StartContainerResponseProto_descriptor,
              new java.lang.String[] { "ServiceResponse", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.StartContainerResponseProto.Builder.class);
          internal_static_StopContainerRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(28);
          internal_static_StopContainerRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_StopContainerRequestProto_descriptor,
              new java.lang.String[] { "ContainerId", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerRequestProto.Builder.class);
          internal_static_StopContainerResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(29);
          internal_static_StopContainerResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_StopContainerResponseProto_descriptor,
              new java.lang.String[] { },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.StopContainerResponseProto.Builder.class);
          internal_static_GetContainerStatusRequestProto_descriptor =
            getDescriptor().getMessageTypes().get(30);
          internal_static_GetContainerStatusRequestProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetContainerStatusRequestProto_descriptor,
              new java.lang.String[] { "ContainerId", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusRequestProto.Builder.class);
          internal_static_GetContainerStatusResponseProto_descriptor =
            getDescriptor().getMessageTypes().get(31);
          internal_static_GetContainerStatusResponseProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetContainerStatusResponseProto_descriptor,
              new java.lang.String[] { "Status", },
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto.class,
              org.apache.hadoop.yarn.proto.YarnServiceProtos.GetContainerStatusResponseProto.Builder.class);
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor(),
        }, assigner);
  }
  
  // @@protoc_insertion_point(outer_class_scope)
}
