// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: MRClientProtocol.proto

package org.apache.hadoop.yarn.proto;

public final class MRClientProtocol {
  private MRClientProtocol() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  public static abstract class MRClientProtocolService
      implements com.google.protobuf.Service {
    protected MRClientProtocolService() {}
    
    public interface Interface {
      public abstract void getJobReport(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto> done);
      
      public abstract void getTaskReport(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto> done);
      
      public abstract void getTaskAttemptReport(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto> done);
      
      public abstract void getCounters(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto> done);
      
      public abstract void getTaskAttemptCompletionEvents(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto> done);
      
      public abstract void getTaskReports(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto> done);
      
      public abstract void getDiagnostics(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto> done);
      
      public abstract void getDelegationToken(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto> done);
      
      public abstract void killJob(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto> done);
      
      public abstract void killTask(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto> done);
      
      public abstract void killTaskAttempt(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto> done);
      
      public abstract void failTaskAttempt(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto> done);
      
    }
    
    public static com.google.protobuf.Service newReflectiveService(
        final Interface impl) {
      return new MRClientProtocolService() {
        @java.lang.Override
        public  void getJobReport(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportRequestProto request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto> done) {
          impl.getJobReport(controller, request, done);
        }
        
        @java.lang.Override
        public  void getTaskReport(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportRequestProto request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto> done) {
          impl.getTaskReport(controller, request, done);
        }
        
        @java.lang.Override
        public  void getTaskAttemptReport(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportRequestProto request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto> done) {
          impl.getTaskAttemptReport(controller, request, done);
        }
        
        @java.lang.Override
        public  void getCounters(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersRequestProto request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto> done) {
          impl.getCounters(controller, request, done);
        }
        
        @java.lang.Override
        public  void getTaskAttemptCompletionEvents(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsRequestProto request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto> done) {
          impl.getTaskAttemptCompletionEvents(controller, request, done);
        }
        
        @java.lang.Override
        public  void getTaskReports(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsRequestProto request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto> done) {
          impl.getTaskReports(controller, request, done);
        }
        
        @java.lang.Override
        public  void getDiagnostics(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsRequestProto request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto> done) {
          impl.getDiagnostics(controller, request, done);
        }
        
        @java.lang.Override
        public  void getDelegationToken(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenRequestProto request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto> done) {
          impl.getDelegationToken(controller, request, done);
        }
        
        @java.lang.Override
        public  void killJob(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobRequestProto request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto> done) {
          impl.killJob(controller, request, done);
        }
        
        @java.lang.Override
        public  void killTask(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskRequestProto request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto> done) {
          impl.killTask(controller, request, done);
        }
        
        @java.lang.Override
        public  void killTaskAttempt(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptRequestProto request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto> done) {
          impl.killTaskAttempt(controller, request, done);
        }
        
        @java.lang.Override
        public  void failTaskAttempt(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptRequestProto request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto> done) {
          impl.failTaskAttempt(controller, request, done);
        }
        
      };
    }
    
    public static com.google.protobuf.BlockingService
        newReflectiveBlockingService(final BlockingInterface impl) {
      return new com.google.protobuf.BlockingService() {
        public final com.google.protobuf.Descriptors.ServiceDescriptor
            getDescriptorForType() {
          return getDescriptor();
        }
        
        public final com.google.protobuf.Message callBlockingMethod(
            com.google.protobuf.Descriptors.MethodDescriptor method,
            com.google.protobuf.RpcController controller,
            com.google.protobuf.Message request)
            throws com.google.protobuf.ServiceException {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.callBlockingMethod() given method descriptor for " +
              "wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return impl.getJobReport(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportRequestProto)request);
            case 1:
              return impl.getTaskReport(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportRequestProto)request);
            case 2:
              return impl.getTaskAttemptReport(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportRequestProto)request);
            case 3:
              return impl.getCounters(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersRequestProto)request);
            case 4:
              return impl.getTaskAttemptCompletionEvents(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsRequestProto)request);
            case 5:
              return impl.getTaskReports(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsRequestProto)request);
            case 6:
              return impl.getDiagnostics(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsRequestProto)request);
            case 7:
              return impl.getDelegationToken(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenRequestProto)request);
            case 8:
              return impl.killJob(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobRequestProto)request);
            case 9:
              return impl.killTask(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskRequestProto)request);
            case 10:
              return impl.killTaskAttempt(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptRequestProto)request);
            case 11:
              return impl.failTaskAttempt(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptRequestProto)request);
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }
        
        public final com.google.protobuf.Message
            getRequestPrototype(
            com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getRequestPrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportRequestProto.getDefaultInstance();
            case 1:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportRequestProto.getDefaultInstance();
            case 2:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportRequestProto.getDefaultInstance();
            case 3:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersRequestProto.getDefaultInstance();
            case 4:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsRequestProto.getDefaultInstance();
            case 5:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsRequestProto.getDefaultInstance();
            case 6:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsRequestProto.getDefaultInstance();
            case 7:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenRequestProto.getDefaultInstance();
            case 8:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobRequestProto.getDefaultInstance();
            case 9:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskRequestProto.getDefaultInstance();
            case 10:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptRequestProto.getDefaultInstance();
            case 11:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptRequestProto.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }
        
        public final com.google.protobuf.Message
            getResponsePrototype(
            com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getResponsePrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto.getDefaultInstance();
            case 1:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto.getDefaultInstance();
            case 2:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto.getDefaultInstance();
            case 3:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto.getDefaultInstance();
            case 4:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto.getDefaultInstance();
            case 5:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto.getDefaultInstance();
            case 6:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto.getDefaultInstance();
            case 7:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto.getDefaultInstance();
            case 8:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto.getDefaultInstance();
            case 9:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto.getDefaultInstance();
            case 10:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto.getDefaultInstance();
            case 11:
              return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }
        
      };
    }
    
    public abstract void getJobReport(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportRequestProto request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto> done);
    
    public abstract void getTaskReport(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportRequestProto request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto> done);
    
    public abstract void getTaskAttemptReport(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportRequestProto request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto> done);
    
    public abstract void getCounters(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersRequestProto request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto> done);
    
    public abstract void getTaskAttemptCompletionEvents(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsRequestProto request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto> done);
    
    public abstract void getTaskReports(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsRequestProto request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto> done);
    
    public abstract void getDiagnostics(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsRequestProto request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto> done);
    
    public abstract void getDelegationToken(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenRequestProto request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto> done);
    
    public abstract void killJob(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobRequestProto request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto> done);
    
    public abstract void killTask(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskRequestProto request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto> done);
    
    public abstract void killTaskAttempt(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptRequestProto request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto> done);
    
    public abstract void failTaskAttempt(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptRequestProto request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto> done);
    
    public static final
        com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.MRClientProtocol.getDescriptor().getServices().get(0);
    }
    public final com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    
    public final void callMethod(
        com.google.protobuf.Descriptors.MethodDescriptor method,
        com.google.protobuf.RpcController controller,
        com.google.protobuf.Message request,
        com.google.protobuf.RpcCallback<
          com.google.protobuf.Message> done) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.callMethod() given method descriptor for wrong " +
          "service type.");
      }
      switch(method.getIndex()) {
        case 0:
          this.getJobReport(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportRequestProto)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto>specializeCallback(
              done));
          return;
        case 1:
          this.getTaskReport(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportRequestProto)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto>specializeCallback(
              done));
          return;
        case 2:
          this.getTaskAttemptReport(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportRequestProto)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto>specializeCallback(
              done));
          return;
        case 3:
          this.getCounters(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersRequestProto)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto>specializeCallback(
              done));
          return;
        case 4:
          this.getTaskAttemptCompletionEvents(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsRequestProto)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto>specializeCallback(
              done));
          return;
        case 5:
          this.getTaskReports(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsRequestProto)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto>specializeCallback(
              done));
          return;
        case 6:
          this.getDiagnostics(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsRequestProto)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto>specializeCallback(
              done));
          return;
        case 7:
          this.getDelegationToken(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenRequestProto)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto>specializeCallback(
              done));
          return;
        case 8:
          this.killJob(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobRequestProto)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto>specializeCallback(
              done));
          return;
        case 9:
          this.killTask(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskRequestProto)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto>specializeCallback(
              done));
          return;
        case 10:
          this.killTaskAttempt(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptRequestProto)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto>specializeCallback(
              done));
          return;
        case 11:
          this.failTaskAttempt(controller, (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptRequestProto)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto>specializeCallback(
              done));
          return;
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }
    
    public final com.google.protobuf.Message
        getRequestPrototype(
        com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getRequestPrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportRequestProto.getDefaultInstance();
        case 1:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportRequestProto.getDefaultInstance();
        case 2:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportRequestProto.getDefaultInstance();
        case 3:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersRequestProto.getDefaultInstance();
        case 4:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsRequestProto.getDefaultInstance();
        case 5:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsRequestProto.getDefaultInstance();
        case 6:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsRequestProto.getDefaultInstance();
        case 7:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenRequestProto.getDefaultInstance();
        case 8:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobRequestProto.getDefaultInstance();
        case 9:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskRequestProto.getDefaultInstance();
        case 10:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptRequestProto.getDefaultInstance();
        case 11:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptRequestProto.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }
    
    public final com.google.protobuf.Message
        getResponsePrototype(
        com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getResponsePrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto.getDefaultInstance();
        case 1:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto.getDefaultInstance();
        case 2:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto.getDefaultInstance();
        case 3:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto.getDefaultInstance();
        case 4:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto.getDefaultInstance();
        case 5:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto.getDefaultInstance();
        case 6:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto.getDefaultInstance();
        case 7:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto.getDefaultInstance();
        case 8:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto.getDefaultInstance();
        case 9:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto.getDefaultInstance();
        case 10:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto.getDefaultInstance();
        case 11:
          return org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }
    
    public static Stub newStub(
        com.google.protobuf.RpcChannel channel) {
      return new Stub(channel);
    }
    
    public static final class Stub extends org.apache.hadoop.yarn.proto.MRClientProtocol.MRClientProtocolService implements Interface {
      private Stub(com.google.protobuf.RpcChannel channel) {
        this.channel = channel;
      }
      
      private final com.google.protobuf.RpcChannel channel;
      
      public com.google.protobuf.RpcChannel getChannel() {
        return channel;
      }
      
      public  void getJobReport(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto.class,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto.getDefaultInstance()));
      }
      
      public  void getTaskReport(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto.class,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto.getDefaultInstance()));
      }
      
      public  void getTaskAttemptReport(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto.class,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto.getDefaultInstance()));
      }
      
      public  void getCounters(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto.class,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto.getDefaultInstance()));
      }
      
      public  void getTaskAttemptCompletionEvents(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(4),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto.class,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto.getDefaultInstance()));
      }
      
      public  void getTaskReports(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(5),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto.class,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto.getDefaultInstance()));
      }
      
      public  void getDiagnostics(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(6),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto.class,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto.getDefaultInstance()));
      }
      
      public  void getDelegationToken(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(7),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto.class,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto.getDefaultInstance()));
      }
      
      public  void killJob(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(8),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto.class,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto.getDefaultInstance()));
      }
      
      public  void killTask(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(9),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto.class,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto.getDefaultInstance()));
      }
      
      public  void killTaskAttempt(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(10),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto.class,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto.getDefaultInstance()));
      }
      
      public  void failTaskAttempt(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptRequestProto request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(11),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto.class,
            org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto.getDefaultInstance()));
      }
    }
    
    public static BlockingInterface newBlockingStub(
        com.google.protobuf.BlockingRpcChannel channel) {
      return new BlockingStub(channel);
    }
    
    public interface BlockingInterface {
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto getJobReport(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportRequestProto request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto getTaskReport(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportRequestProto request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto getTaskAttemptReport(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportRequestProto request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto getCounters(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersRequestProto request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto getTaskAttemptCompletionEvents(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsRequestProto request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto getTaskReports(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsRequestProto request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto getDiagnostics(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsRequestProto request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto getDelegationToken(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenRequestProto request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto killJob(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobRequestProto request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto killTask(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskRequestProto request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto killTaskAttempt(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptRequestProto request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto failTaskAttempt(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptRequestProto request)
          throws com.google.protobuf.ServiceException;
    }
    
    private static final class BlockingStub implements BlockingInterface {
      private BlockingStub(com.google.protobuf.BlockingRpcChannel channel) {
        this.channel = channel;
      }
      
      private final com.google.protobuf.BlockingRpcChannel channel;
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto getJobReport(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportRequestProto request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto) channel.callBlockingMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetJobReportResponseProto.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto getTaskReport(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportRequestProto request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto) channel.callBlockingMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportResponseProto.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto getTaskAttemptReport(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportRequestProto request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto) channel.callBlockingMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptReportResponseProto.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto getCounters(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersRequestProto request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto) channel.callBlockingMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetCountersResponseProto.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto getTaskAttemptCompletionEvents(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsRequestProto request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto) channel.callBlockingMethod(
          getDescriptor().getMethods().get(4),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskAttemptCompletionEventsResponseProto.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto getTaskReports(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsRequestProto request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto) channel.callBlockingMethod(
          getDescriptor().getMethods().get(5),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetTaskReportsResponseProto.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto getDiagnostics(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsRequestProto request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto) channel.callBlockingMethod(
          getDescriptor().getMethods().get(6),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDiagnosticsResponseProto.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto getDelegationToken(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenRequestProto request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto) channel.callBlockingMethod(
          getDescriptor().getMethods().get(7),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.GetDelegationTokenResponseProto.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto killJob(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobRequestProto request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto) channel.callBlockingMethod(
          getDescriptor().getMethods().get(8),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillJobResponseProto.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto killTask(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskRequestProto request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto) channel.callBlockingMethod(
          getDescriptor().getMethods().get(9),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskResponseProto.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto killTaskAttempt(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptRequestProto request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto) channel.callBlockingMethod(
          getDescriptor().getMethods().get(10),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.KillTaskAttemptResponseProto.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto failTaskAttempt(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptRequestProto request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto) channel.callBlockingMethod(
          getDescriptor().getMethods().get(11),
          controller,
          request,
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.FailTaskAttemptResponseProto.getDefaultInstance());
      }
      
    }
  }
  
  
  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\026MRClientProtocol.proto\032\027mr_service_pro" +
      "tos.proto2\320\007\n\027MRClientProtocolService\022E\n" +
      "\014getJobReport\022\031.GetJobReportRequestProto" +
      "\032\032.GetJobReportResponseProto\022H\n\rgetTaskR" +
      "eport\022\032.GetTaskReportRequestProto\032\033.GetT" +
      "askReportResponseProto\022]\n\024getTaskAttempt" +
      "Report\022!.GetTaskAttemptReportRequestProt" +
      "o\032\".GetTaskAttemptReportResponseProto\022B\n" +
      "\013getCounters\022\030.GetCountersRequestProto\032\031" +
      ".GetCountersResponseProto\022{\n\036getTaskAtte",
      "mptCompletionEvents\022+.GetTaskAttemptComp" +
      "letionEventsRequestProto\032,.GetTaskAttemp" +
      "tCompletionEventsResponseProto\022K\n\016getTas" +
      "kReports\022\033.GetTaskReportsRequestProto\032\034." +
      "GetTaskReportsResponseProto\022K\n\016getDiagno" +
      "stics\022\033.GetDiagnosticsRequestProto\032\034.Get" +
      "DiagnosticsResponseProto\022W\n\022getDelegatio" +
      "nToken\022\037.GetDelegationTokenRequestProto\032" +
      " .GetDelegationTokenResponseProto\0226\n\007kil" +
      "lJob\022\024.KillJobRequestProto\032\025.KillJobResp",
      "onseProto\0229\n\010killTask\022\025.KillTaskRequestP" +
      "roto\032\026.KillTaskResponseProto\022N\n\017killTask" +
      "Attempt\022\034.KillTaskAttemptRequestProto\032\035." +
      "KillTaskAttemptResponseProto\022N\n\017failTask" +
      "Attempt\022\034.FailTaskAttemptRequestProto\032\035." +
      "FailTaskAttemptResponseProtoB3\n\034org.apac" +
      "he.hadoop.yarn.protoB\020MRClientProtocol\210\001" +
      "\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.mapreduce.v2.proto.MRServiceProtos.getDescriptor(),
        }, assigner);
  }
  
  // @@protoc_insertion_point(outer_class_scope)
}
